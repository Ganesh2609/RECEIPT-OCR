{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from model import InvoiceGCN\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# device agnostic code \n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device='cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_test_split(save_fd):\n",
    "    # import pdb; pdb.set_trace()\n",
    "    train_data = torch.load(os.path.join(save_fd, 'train_data.dataset'))\n",
    "    test_data = torch.load(os.path.join(save_fd, 'test_data.dataset'))\n",
    "    return train_data, test_data\n",
    "\n",
    "\n",
    "train_data, test_data = load_train_test_split(save_fd='sroie-2019/processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = InvoiceGCN(input_dim=train_data.x.shape[1], chebnet=True).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.9)\n",
    "\n",
    "train_data = train_data.to(device)\n",
    "test_data = test_data.to(device)\n",
    "\n",
    "_class_weights = compute_class_weight(class_weight='balanced',\n",
    "                                      classes=train_data.y.unique().cpu().numpy(),\n",
    "                                      y=train_data.y.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.32284892874255594\n",
      "test accuracy: 0.35549930971007826\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.02      0.65      0.04        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00        17\n",
      "           3       0.02      0.05      0.03       168\n",
      "           4       0.93      0.37      0.52      4112\n",
      "\n",
      "    accuracy                           0.36      4346\n",
      "   macro avg       0.19      0.21      0.12      4346\n",
      "weighted avg       0.88      0.36      0.50      4346\n",
      "\n",
      "Epoch:   0, train_loss: 11.5788, val_loss: 2.0841\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.18700800876172222\n",
      "test accuracy: 0.1859180855959503\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.78      0.18        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.02      0.24      0.04        17\n",
      "           3       0.05      0.83      0.09       168\n",
      "           4       0.95      0.15      0.26      4112\n",
      "\n",
      "    accuracy                           0.19      4346\n",
      "   macro avg       0.23      0.40      0.12      4346\n",
      "weighted avg       0.90      0.19      0.25      4346\n",
      "\n",
      "Epoch:  10, train_loss: 2.0014, val_loss: 1.5684\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.18978027243480047\n",
      "test accuracy: 0.20317533364012885\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.92      0.15        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.03      0.53      0.06        17\n",
      "           3       0.05      0.85      0.10       168\n",
      "           4       0.96      0.17      0.28      4112\n",
      "\n",
      "    accuracy                           0.20      4346\n",
      "   macro avg       0.23      0.49      0.12      4346\n",
      "weighted avg       0.91      0.20      0.28      4346\n",
      "\n",
      "Epoch:  20, train_loss: 1.4425, val_loss: 1.6435\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.30067081935793005\n",
      "test accuracy: 0.30326737229636447\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.92      0.14        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.04      0.59      0.07        17\n",
      "           3       0.06      0.77      0.12       168\n",
      "           4       0.97      0.28      0.43      4112\n",
      "\n",
      "    accuracy                           0.30      4346\n",
      "   macro avg       0.23      0.51      0.15      4346\n",
      "weighted avg       0.92      0.30      0.41      4346\n",
      "\n",
      "Epoch:  30, train_loss: 1.1896, val_loss: 1.4581\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.30399069067013484\n",
      "test accuracy: 0.3120110446387483\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.96      0.17        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.04      0.82      0.08        17\n",
      "           3       0.07      0.90      0.13       168\n",
      "           4       0.99      0.28      0.43      4112\n",
      "\n",
      "    accuracy                           0.31      4346\n",
      "   macro avg       0.24      0.59      0.16      4346\n",
      "weighted avg       0.94      0.31      0.42      4346\n",
      "\n",
      "Epoch:  40, train_loss: 0.9833, val_loss: 1.4444\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.3028954753918817\n",
      "test accuracy: 0.305798435342844\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.96      0.18        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.07      0.94      0.13        17\n",
      "           3       0.07      0.98      0.13       168\n",
      "           4       1.00      0.27      0.42      4112\n",
      "\n",
      "    accuracy                           0.31      4346\n",
      "   macro avg       0.25      0.63      0.17      4346\n",
      "weighted avg       0.95      0.31      0.41      4346\n",
      "\n",
      "Epoch:  50, train_loss: 0.8551, val_loss: 1.4096\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.4124512286946403\n",
      "test accuracy: 0.42406810860561434\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.96      0.19        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.07      0.94      0.12        17\n",
      "           3       0.09      0.95      0.16       168\n",
      "           4       1.00      0.39      0.56      4112\n",
      "\n",
      "    accuracy                           0.42      4346\n",
      "   macro avg       0.25      0.65      0.21      4346\n",
      "weighted avg       0.95      0.42      0.54      4346\n",
      "\n",
      "Epoch:  60, train_loss: 0.7700, val_loss: 1.2685\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.5048942432746937\n",
      "test accuracy: 0.5158766682006443\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.96      0.19        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.09      1.00      0.17        17\n",
      "           3       0.10      0.92      0.18       168\n",
      "           4       0.99      0.49      0.66      4112\n",
      "\n",
      "    accuracy                           0.52      4346\n",
      "   macro avg       0.26      0.67      0.24      4346\n",
      "weighted avg       0.95      0.52      0.63      4346\n",
      "\n",
      "Epoch:  70, train_loss: 0.7173, val_loss: 1.1869\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.5145458279142994\n",
      "test accuracy: 0.5227795674183157\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.98      0.20        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.08      1.00      0.15        17\n",
      "           3       0.11      0.96      0.19       168\n",
      "           4       1.00      0.50      0.66      4112\n",
      "\n",
      "    accuracy                           0.52      4346\n",
      "   macro avg       0.26      0.69      0.24      4346\n",
      "weighted avg       0.95      0.52      0.64      4346\n",
      "\n",
      "Epoch:  80, train_loss: 0.6402, val_loss: 1.1500\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.5352522417687727\n",
      "test accuracy: 0.5375057524160147\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.98      0.21        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.10      1.00      0.18        17\n",
      "           3       0.11      0.97      0.19       168\n",
      "           4       1.00      0.51      0.68      4112\n",
      "\n",
      "    accuracy                           0.54      4346\n",
      "   macro avg       0.27      0.69      0.25      4346\n",
      "weighted avg       0.95      0.54      0.65      4346\n",
      "\n",
      "Epoch:  90, train_loss: 0.5934, val_loss: 1.0855\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.6239304538298309\n",
      "test accuracy: 0.6343764381040037\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.98      0.19        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.11      1.00      0.20        17\n",
      "           3       0.14      0.94      0.25       168\n",
      "           4       1.00      0.62      0.76      4112\n",
      "\n",
      "    accuracy                           0.63      4346\n",
      "   macro avg       0.27      0.71      0.28      4346\n",
      "weighted avg       0.95      0.63      0.73      4346\n",
      "\n",
      "Epoch: 100, train_loss: 0.5418, val_loss: 0.9945\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.6384078307892395\n",
      "test accuracy: 0.6424298205246204\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.98      0.21        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.11      1.00      0.20        17\n",
      "           3       0.15      0.94      0.25       168\n",
      "           4       1.00      0.62      0.77      4112\n",
      "\n",
      "    accuracy                           0.64      4346\n",
      "   macro avg       0.27      0.71      0.29      4346\n",
      "weighted avg       0.95      0.64      0.74      4346\n",
      "\n",
      "Epoch: 110, train_loss: 0.4869, val_loss: 0.9556\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.6709562598398248\n",
      "test accuracy: 0.674643350207087\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.98      0.21        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.13      1.00      0.23        17\n",
      "           3       0.16      0.95      0.27       168\n",
      "           4       1.00      0.66      0.79      4112\n",
      "\n",
      "    accuracy                           0.67      4346\n",
      "   macro avg       0.28      0.72      0.30      4346\n",
      "weighted avg       0.95      0.67      0.76      4346\n",
      "\n",
      "Epoch: 120, train_loss: 0.4539, val_loss: 0.8769\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.6795126292011774\n",
      "test accuracy: 0.6838472158306489\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.98      0.21        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.13      1.00      0.23        17\n",
      "           3       0.17      0.95      0.29       168\n",
      "           4       1.00      0.67      0.80      4112\n",
      "\n",
      "    accuracy                           0.68      4346\n",
      "   macro avg       0.28      0.72      0.31      4346\n",
      "weighted avg       0.95      0.68      0.77      4346\n",
      "\n",
      "Epoch: 130, train_loss: 0.4937, val_loss: 0.8730\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.7009377780820042\n",
      "test accuracy: 0.7066267832489646\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.13      0.98      0.22        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.16      1.00      0.27        17\n",
      "           3       0.18      0.95      0.30       168\n",
      "           4       1.00      0.69      0.82      4112\n",
      "\n",
      "    accuracy                           0.71      4346\n",
      "   macro avg       0.29      0.72      0.32      4346\n",
      "weighted avg       0.95      0.71      0.79      4346\n",
      "\n",
      "Epoch: 140, train_loss: 0.4012, val_loss: 0.8035\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.7232527893764118\n",
      "test accuracy: 0.7305568338702255\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.13      0.98      0.23        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.15      1.00      0.25        17\n",
      "           3       0.20      0.94      0.33       168\n",
      "           4       1.00      0.72      0.83      4112\n",
      "\n",
      "    accuracy                           0.73      4346\n",
      "   macro avg       0.29      0.73      0.33      4346\n",
      "weighted avg       0.95      0.73      0.81      4346\n",
      "\n",
      "Epoch: 150, train_loss: 0.3934, val_loss: 0.7585\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.7402628516667807\n",
      "test accuracy: 0.7473538886332259\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.13      0.98      0.24        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.16      1.00      0.28        17\n",
      "           3       0.21      0.95      0.34       168\n",
      "           4       1.00      0.74      0.85      4112\n",
      "\n",
      "    accuracy                           0.75      4346\n",
      "   macro avg       0.30      0.73      0.34      4346\n",
      "weighted avg       0.95      0.75      0.82      4346\n",
      "\n",
      "Epoch: 160, train_loss: 0.3538, val_loss: 0.7264\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.7524128961599015\n",
      "test accuracy: 0.7586286240220893\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.98      0.25        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.18      1.00      0.30        17\n",
      "           3       0.21      0.95      0.35       168\n",
      "           4       1.00      0.75      0.85      4112\n",
      "\n",
      "    accuracy                           0.76      4346\n",
      "   macro avg       0.31      0.74      0.35      4346\n",
      "weighted avg       0.95      0.76      0.83      4346\n",
      "\n",
      "Epoch: 170, train_loss: 0.3370, val_loss: 0.6781\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.7562461496337874\n",
      "test accuracy: 0.7648412333179936\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.98      0.27        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.18      1.00      0.31        17\n",
      "           3       0.22      0.96      0.35       168\n",
      "           4       1.00      0.75      0.86      4112\n",
      "\n",
      "    accuracy                           0.76      4346\n",
      "   macro avg       0.31      0.74      0.36      4346\n",
      "weighted avg       0.95      0.76      0.83      4346\n",
      "\n",
      "Epoch: 180, train_loss: 0.3724, val_loss: 0.6522\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.7600109521527826\n",
      "test accuracy: 0.7692130694891854\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.98      0.25        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.18      1.00      0.30        17\n",
      "           3       0.22      0.96      0.36       168\n",
      "           4       1.00      0.76      0.86      4112\n",
      "\n",
      "    accuracy                           0.77      4346\n",
      "   macro avg       0.31      0.74      0.36      4346\n",
      "weighted avg       0.95      0.77      0.83      4346\n",
      "\n",
      "Epoch: 190, train_loss: 0.3339, val_loss: 0.6416\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.7620302553220617\n",
      "test accuracy: 0.7777266451909802\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.98      0.28        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.21      1.00      0.35        17\n",
      "           3       0.23      0.98      0.37       168\n",
      "           4       1.00      0.77      0.87      4112\n",
      "\n",
      "    accuracy                           0.78      4346\n",
      "   macro avg       0.32      0.74      0.37      4346\n",
      "weighted avg       0.96      0.78      0.84      4346\n",
      "\n",
      "Epoch: 200, train_loss: 0.3196, val_loss: 0.6197\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.7860565404887399\n",
      "test accuracy: 0.7998159226875288\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.98      0.30        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.20      1.00      0.33        17\n",
      "           3       0.24      0.96      0.38       168\n",
      "           4       1.00      0.79      0.88      4112\n",
      "\n",
      "    accuracy                           0.80      4346\n",
      "   macro avg       0.32      0.75      0.38      4346\n",
      "weighted avg       0.96      0.80      0.85      4346\n",
      "\n",
      "Epoch: 210, train_loss: 0.3105, val_loss: 0.5652\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.7916352933123417\n",
      "test accuracy: 0.8071790151863782\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.98      0.32        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.23      1.00      0.37        17\n",
      "           3       0.24      0.98      0.38       168\n",
      "           4       1.00      0.80      0.89      4112\n",
      "\n",
      "    accuracy                           0.81      4346\n",
      "   macro avg       0.33      0.75      0.39      4346\n",
      "weighted avg       0.96      0.81      0.86      4346\n",
      "\n",
      "Epoch: 220, train_loss: 0.2754, val_loss: 0.5504\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.793996851256075\n",
      "test accuracy: 0.8101702715140359\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.98      0.33        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.21      1.00      0.35        17\n",
      "           3       0.24      0.98      0.39       168\n",
      "           4       1.00      0.80      0.89      4112\n",
      "\n",
      "    accuracy                           0.81      4346\n",
      "   macro avg       0.33      0.75      0.39      4346\n",
      "weighted avg       0.96      0.81      0.86      4346\n",
      "\n",
      "Epoch: 230, train_loss: 0.2539, val_loss: 0.5512\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.8029639263467725\n",
      "test accuracy: 0.8168430740911182\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.98      0.34        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.22      1.00      0.37        17\n",
      "           3       0.25      0.97      0.40       168\n",
      "           4       1.00      0.81      0.89      4112\n",
      "\n",
      "    accuracy                           0.82      4346\n",
      "   macro avg       0.34      0.75      0.40      4346\n",
      "weighted avg       0.96      0.82      0.87      4346\n",
      "\n",
      "Epoch: 240, train_loss: 0.2464, val_loss: 0.5286\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.8241837223629269\n",
      "test accuracy: 0.8384721583064887\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.98      0.39        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.23      1.00      0.37        17\n",
      "           3       0.27      0.96      0.42       168\n",
      "           4       1.00      0.83      0.91      4112\n",
      "\n",
      "    accuracy                           0.84      4346\n",
      "   macro avg       0.35      0.75      0.42      4346\n",
      "weighted avg       0.96      0.84      0.88      4346\n",
      "\n",
      "Epoch: 250, train_loss: 0.2539, val_loss: 0.4729\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.8297282497090834\n",
      "test accuracy: 0.8433041877588587\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.98      0.39        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.23      1.00      0.37        17\n",
      "           3       0.27      0.96      0.43       168\n",
      "           4       1.00      0.84      0.91      4112\n",
      "\n",
      "    accuracy                           0.84      4346\n",
      "   macro avg       0.35      0.75      0.42      4346\n",
      "weighted avg       0.96      0.84      0.88      4346\n",
      "\n",
      "Epoch: 260, train_loss: 0.2286, val_loss: 0.4566\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.8220617427613115\n",
      "test accuracy: 0.8364012885411873\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.98      0.36        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.22      1.00      0.37        17\n",
      "           3       0.27      0.97      0.42       168\n",
      "           4       1.00      0.83      0.91      4112\n",
      "\n",
      "    accuracy                           0.84      4346\n",
      "   macro avg       0.34      0.76      0.41      4346\n",
      "weighted avg       0.96      0.84      0.88      4346\n",
      "\n",
      "Epoch: 270, train_loss: 0.2334, val_loss: 0.4726\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.8438291464165925\n",
      "test accuracy: 0.8573400828347906\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.98      0.45        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.22      1.00      0.37        17\n",
      "           3       0.29      0.96      0.44       168\n",
      "           4       1.00      0.85      0.92      4112\n",
      "\n",
      "    accuracy                           0.86      4346\n",
      "   macro avg       0.36      0.76      0.44      4346\n",
      "weighted avg       0.96      0.86      0.89      4346\n",
      "\n",
      "Epoch: 280, train_loss: 0.2212, val_loss: 0.4235\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.854541720857006\n",
      "test accuracy: 0.8681546249424759\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.98      0.42        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.24      1.00      0.38        17\n",
      "           3       0.32      0.96      0.49       168\n",
      "           4       1.00      0.86      0.93      4112\n",
      "\n",
      "    accuracy                           0.87      4346\n",
      "   macro avg       0.37      0.76      0.44      4346\n",
      "weighted avg       0.96      0.87      0.90      4346\n",
      "\n",
      "Epoch: 290, train_loss: 0.2112, val_loss: 0.4010\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.8615237182558697\n",
      "test accuracy: 0.8713759779107225\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.98      0.45        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.25      1.00      0.40        17\n",
      "           3       0.31      0.97      0.47       168\n",
      "           4       1.00      0.87      0.93      4112\n",
      "\n",
      "    accuracy                           0.87      4346\n",
      "   macro avg       0.37      0.76      0.45      4346\n",
      "weighted avg       0.96      0.87      0.90      4346\n",
      "\n",
      "Epoch: 300, train_loss: 0.2032, val_loss: 0.3821\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.8637825997672668\n",
      "test accuracy: 0.873676944316613\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.98      0.47        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.28      1.00      0.44        17\n",
      "           3       0.31      0.97      0.47       168\n",
      "           4       1.00      0.87      0.93      4112\n",
      "\n",
      "    accuracy                           0.87      4346\n",
      "   macro avg       0.38      0.76      0.46      4346\n",
      "weighted avg       0.96      0.87      0.90      4346\n",
      "\n",
      "Epoch: 310, train_loss: 0.1918, val_loss: 0.3744\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.8720651653090561\n",
      "test accuracy: 0.878508973768983\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.98      0.49        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.27      1.00      0.43        17\n",
      "           3       0.31      0.96      0.47       168\n",
      "           4       1.00      0.87      0.93      4112\n",
      "\n",
      "    accuracy                           0.88      4346\n",
      "   macro avg       0.38      0.76      0.46      4346\n",
      "weighted avg       0.96      0.88      0.91      4346\n",
      "\n",
      "Epoch: 320, train_loss: 0.1930, val_loss: 0.3560\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.8819221028133343\n",
      "test accuracy: 0.8874827427519558\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.98      0.54        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.31      1.00      0.47        17\n",
      "           3       0.32      0.97      0.48       168\n",
      "           4       1.00      0.88      0.94      4112\n",
      "\n",
      "    accuracy                           0.89      4346\n",
      "   macro avg       0.40      0.77      0.49      4346\n",
      "weighted avg       0.96      0.89      0.91      4346\n",
      "\n",
      "Epoch: 330, train_loss: 0.1789, val_loss: 0.3332\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.8816140735163256\n",
      "test accuracy: 0.8877128393925449\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.98      0.54        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.30      1.00      0.46        17\n",
      "           3       0.32      0.96      0.48       168\n",
      "           4       1.00      0.88      0.94      4112\n",
      "\n",
      "    accuracy                           0.89      4346\n",
      "   macro avg       0.40      0.77      0.48      4346\n",
      "weighted avg       0.96      0.89      0.91      4346\n",
      "\n",
      "Epoch: 340, train_loss: 0.1826, val_loss: 0.3388\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.8845232390991854\n",
      "test accuracy: 0.8900138057984354\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.98      0.54        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.29      1.00      0.45        17\n",
      "           3       0.32      0.96      0.49       168\n",
      "           4       1.00      0.89      0.94      4112\n",
      "\n",
      "    accuracy                           0.89      4346\n",
      "   macro avg       0.40      0.77      0.48      4346\n",
      "weighted avg       0.96      0.89      0.91      4346\n",
      "\n",
      "Epoch: 350, train_loss: 0.1625, val_loss: 0.3340\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.8918132657950578\n",
      "test accuracy: 0.8939254486884491\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.98      0.56        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.29      1.00      0.45        17\n",
      "           3       0.33      0.96      0.49       168\n",
      "           4       1.00      0.89      0.94      4112\n",
      "\n",
      "    accuracy                           0.89      4346\n",
      "   macro avg       0.40      0.77      0.49      4346\n",
      "weighted avg       0.96      0.89      0.92      4346\n",
      "\n",
      "Epoch: 360, train_loss: 0.1666, val_loss: 0.3172\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.8905469231295776\n",
      "test accuracy: 0.8925448688449149\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.98      0.55        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.30      1.00      0.47        17\n",
      "           3       0.33      0.96      0.49       168\n",
      "           4       1.00      0.89      0.94      4112\n",
      "\n",
      "    accuracy                           0.89      4346\n",
      "   macro avg       0.40      0.77      0.49      4346\n",
      "weighted avg       0.96      0.89      0.92      4346\n",
      "\n",
      "Epoch: 370, train_loss: 0.1650, val_loss: 0.3226\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.8992744198781573\n",
      "test accuracy: 0.898067188219052\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.98      0.57        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.34      1.00      0.51        17\n",
      "           3       0.33      0.96      0.49       168\n",
      "           4       1.00      0.89      0.94      4112\n",
      "\n",
      "    accuracy                           0.90      4346\n",
      "   macro avg       0.42      0.77      0.50      4346\n",
      "weighted avg       0.96      0.90      0.92      4346\n",
      "\n",
      "Epoch: 380, train_loss: 0.1731, val_loss: 0.2961\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9041686631528509\n",
      "test accuracy: 0.9042797975149562\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.98      0.60        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.32      1.00      0.49        17\n",
      "           3       0.35      0.96      0.51       168\n",
      "           4       1.00      0.90      0.95      4112\n",
      "\n",
      "    accuracy                           0.90      4346\n",
      "   macro avg       0.42      0.77      0.51      4346\n",
      "weighted avg       0.96      0.90      0.92      4346\n",
      "\n",
      "Epoch: 390, train_loss: 0.1448, val_loss: 0.2838\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9067013484838113\n",
      "test accuracy: 0.9040497008743672\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.98      0.59        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.34      1.00      0.51        17\n",
      "           3       0.35      0.96      0.51       168\n",
      "           4       1.00      0.90      0.95      4112\n",
      "\n",
      "    accuracy                           0.90      4346\n",
      "   macro avg       0.42      0.77      0.51      4346\n",
      "weighted avg       0.96      0.90      0.92      4346\n",
      "\n",
      "Epoch: 400, train_loss: 0.1552, val_loss: 0.2791\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9103634745704703\n",
      "test accuracy: 0.9093419236079153\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.98      0.60        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.35      1.00      0.52        17\n",
      "           3       0.36      0.96      0.52       168\n",
      "           4       1.00      0.91      0.95      4112\n",
      "\n",
      "    accuracy                           0.91      4346\n",
      "   macro avg       0.43      0.77      0.52      4346\n",
      "weighted avg       0.96      0.91      0.93      4346\n",
      "\n",
      "Epoch: 410, train_loss: 0.1436, val_loss: 0.2657\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9147101102060373\n",
      "test accuracy: 0.9132535664979291\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.98      0.64        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.37      1.00      0.54        17\n",
      "           3       0.36      0.96      0.53       168\n",
      "           4       1.00      0.91      0.95      4112\n",
      "\n",
      "    accuracy                           0.91      4346\n",
      "   macro avg       0.44      0.77      0.53      4346\n",
      "weighted avg       0.97      0.91      0.93      4346\n",
      "\n",
      "Epoch: 420, train_loss: 0.1348, val_loss: 0.2506\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.8959203230885071\n",
      "test accuracy: 0.8978370915784629\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.98      0.55        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.29      1.00      0.45        17\n",
      "           3       0.34      0.96      0.51       168\n",
      "           4       1.00      0.89      0.94      4112\n",
      "\n",
      "    accuracy                           0.90      4346\n",
      "   macro avg       0.40      0.77      0.49      4346\n",
      "weighted avg       0.96      0.90      0.92      4346\n",
      "\n",
      "Epoch: 430, train_loss: 0.1382, val_loss: 0.3098\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9187829420220412\n",
      "test accuracy: 0.9162448228255867\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.98      0.62        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.33      1.00      0.49        17\n",
      "           3       0.38      0.95      0.55       168\n",
      "           4       1.00      0.91      0.95      4112\n",
      "\n",
      "    accuracy                           0.92      4346\n",
      "   macro avg       0.43      0.77      0.52      4346\n",
      "weighted avg       0.97      0.92      0.93      4346\n",
      "\n",
      "Epoch: 440, train_loss: 0.1303, val_loss: 0.2377\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9072489561229379\n",
      "test accuracy: 0.9052001840773125\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.98      0.61        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.35      1.00      0.52        17\n",
      "           3       0.34      0.96      0.51       168\n",
      "           4       1.00      0.90      0.95      4112\n",
      "\n",
      "    accuracy                           0.91      4346\n",
      "   macro avg       0.43      0.77      0.52      4346\n",
      "weighted avg       0.96      0.91      0.92      4346\n",
      "\n",
      "Epoch: 450, train_loss: 0.1204, val_loss: 0.2742\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9171743445821069\n",
      "test accuracy: 0.9141739530602854\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.98      0.62        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.38      1.00      0.55        17\n",
      "           3       0.37      0.95      0.53       168\n",
      "           4       1.00      0.91      0.95      4112\n",
      "\n",
      "    accuracy                           0.91      4346\n",
      "   macro avg       0.44      0.77      0.53      4346\n",
      "weighted avg       0.96      0.91      0.93      4346\n",
      "\n",
      "Epoch: 460, train_loss: 0.1281, val_loss: 0.2418\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9203230885070847\n",
      "test accuracy: 0.9194661757938334\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.98      0.63        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.38      1.00      0.55        17\n",
      "           3       0.39      0.95      0.55       168\n",
      "           4       1.00      0.92      0.96      4112\n",
      "\n",
      "    accuracy                           0.92      4346\n",
      "   macro avg       0.45      0.77      0.54      4346\n",
      "weighted avg       0.97      0.92      0.93      4346\n",
      "\n",
      "Epoch: 470, train_loss: 0.1227, val_loss: 0.2303\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9213840783078924\n",
      "test accuracy: 0.9190059825126553\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.98      0.67        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.35      1.00      0.52        17\n",
      "           3       0.38      0.95      0.54       168\n",
      "           4       1.00      0.92      0.96      4112\n",
      "\n",
      "    accuracy                           0.92      4346\n",
      "   macro avg       0.45      0.77      0.54      4346\n",
      "weighted avg       0.97      0.92      0.93      4346\n",
      "\n",
      "Epoch: 480, train_loss: 0.1142, val_loss: 0.2314\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9212471763981107\n",
      "test accuracy: 0.9178554993097101\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.98      0.67        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.42      1.00      0.60        17\n",
      "           3       0.37      0.95      0.53       168\n",
      "           4       1.00      0.92      0.95      4112\n",
      "\n",
      "    accuracy                           0.92      4346\n",
      "   macro avg       0.46      0.77      0.55      4346\n",
      "weighted avg       0.97      0.92      0.93      4346\n",
      "\n",
      "Epoch: 490, train_loss: 0.1203, val_loss: 0.2329\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.921520980217674\n",
      "test accuracy: 0.9196962724344224\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.98      0.66        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.40      1.00      0.57        17\n",
      "           3       0.38      0.96      0.54       168\n",
      "           4       1.00      0.92      0.96      4112\n",
      "\n",
      "    accuracy                           0.92      4346\n",
      "   macro avg       0.45      0.77      0.55      4346\n",
      "weighted avg       0.97      0.92      0.93      4346\n",
      "\n",
      "Epoch: 500, train_loss: 0.1162, val_loss: 0.2283\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9302142514888083\n",
      "test accuracy: 0.9286700414173953\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.98      0.72        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.42      1.00      0.60        17\n",
      "           3       0.40      0.95      0.57       168\n",
      "           4       1.00      0.93      0.96      4112\n",
      "\n",
      "    accuracy                           0.93      4346\n",
      "   macro avg       0.48      0.77      0.57      4346\n",
      "weighted avg       0.97      0.93      0.94      4346\n",
      "\n",
      "Epoch: 510, train_loss: 0.1160, val_loss: 0.2041\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9191251967964953\n",
      "test accuracy: 0.9180855959502991\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.98      0.60        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.33      1.00      0.49        17\n",
      "           3       0.40      0.95      0.56       168\n",
      "           4       1.00      0.92      0.95      4112\n",
      "\n",
      "    accuracy                           0.92      4346\n",
      "   macro avg       0.43      0.77      0.52      4346\n",
      "weighted avg       0.97      0.92      0.93      4346\n",
      "\n",
      "Epoch: 520, train_loss: 0.1162, val_loss: 0.2343\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.920186186597303\n",
      "test accuracy: 0.917395306028532\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.98      0.64        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.36      1.00      0.53        17\n",
      "           3       0.38      0.95      0.54       168\n",
      "           4       1.00      0.91      0.95      4112\n",
      "\n",
      "    accuracy                           0.92      4346\n",
      "   macro avg       0.44      0.77      0.53      4346\n",
      "weighted avg       0.97      0.92      0.93      4346\n",
      "\n",
      "Epoch: 530, train_loss: 0.1120, val_loss: 0.2309\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9195359025258403\n",
      "test accuracy: 0.9144040497008744\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.98      0.64        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.40      1.00      0.58        17\n",
      "           3       0.36      0.96      0.53       168\n",
      "           4       1.00      0.91      0.95      4112\n",
      "\n",
      "    accuracy                           0.91      4346\n",
      "   macro avg       0.45      0.77      0.54      4346\n",
      "weighted avg       0.97      0.91      0.93      4346\n",
      "\n",
      "Epoch: 540, train_loss: 0.1204, val_loss: 0.2405\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.920939147101102\n",
      "test accuracy: 0.9169351127473538\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.98      0.67        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.42      1.00      0.60        17\n",
      "           3       0.36      0.96      0.53       168\n",
      "           4       1.00      0.91      0.95      4112\n",
      "\n",
      "    accuracy                           0.92      4346\n",
      "   macro avg       0.46      0.77      0.55      4346\n",
      "weighted avg       0.97      0.92      0.93      4346\n",
      "\n",
      "Epoch: 550, train_loss: 0.1089, val_loss: 0.2335\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9293928400301185\n",
      "test accuracy: 0.9263690750115048\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.98      0.72        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.50      1.00      0.67        17\n",
      "           3       0.39      0.96      0.55       168\n",
      "           4       1.00      0.92      0.96      4112\n",
      "\n",
      "    accuracy                           0.93      4346\n",
      "   macro avg       0.49      0.77      0.58      4346\n",
      "weighted avg       0.97      0.93      0.94      4346\n",
      "\n",
      "Epoch: 560, train_loss: 0.1148, val_loss: 0.2100\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9324389075227599\n",
      "test accuracy: 0.9279797514956282\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.98      0.73        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.53      1.00      0.69        17\n",
      "           3       0.39      0.96      0.55       168\n",
      "           4       1.00      0.93      0.96      4112\n",
      "\n",
      "    accuracy                           0.93      4346\n",
      "   macro avg       0.50      0.77      0.59      4346\n",
      "weighted avg       0.97      0.93      0.94      4346\n",
      "\n",
      "Epoch: 570, train_loss: 0.1110, val_loss: 0.2030\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9285714285714286\n",
      "test accuracy: 0.9247583985273815\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.98      0.72        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.49      1.00      0.65        17\n",
      "           3       0.38      0.96      0.55       168\n",
      "           4       1.00      0.92      0.96      4112\n",
      "\n",
      "    accuracy                           0.92      4346\n",
      "   macro avg       0.49      0.77      0.57      4346\n",
      "weighted avg       0.97      0.92      0.94      4346\n",
      "\n",
      "Epoch: 580, train_loss: 0.0992, val_loss: 0.2088\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9375727291395715\n",
      "test accuracy: 0.9353428439944776\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.98      0.71        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.47      1.00      0.64        17\n",
      "           3       0.43      0.95      0.59       168\n",
      "           4       1.00      0.93      0.96      4112\n",
      "\n",
      "    accuracy                           0.94      4346\n",
      "   macro avg       0.49      0.77      0.58      4346\n",
      "weighted avg       0.97      0.94      0.95      4346\n",
      "\n",
      "Epoch: 590, train_loss: 0.0963, val_loss: 0.1836\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.933362995413786\n",
      "test accuracy: 0.9284399447768062\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.98      0.71        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.45      1.00      0.62        17\n",
      "           3       0.40      0.96      0.56       168\n",
      "           4       1.00      0.93      0.96      4112\n",
      "\n",
      "    accuracy                           0.93      4346\n",
      "   macro avg       0.48      0.77      0.57      4346\n",
      "weighted avg       0.97      0.93      0.94      4346\n",
      "\n",
      "Epoch: 600, train_loss: 0.0908, val_loss: 0.1963\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9390444246697242\n",
      "test accuracy: 0.9362632305568339\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.98      0.70        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.42      1.00      0.60        17\n",
      "           3       0.44      0.95      0.60       168\n",
      "           4       1.00      0.93      0.97      4112\n",
      "\n",
      "    accuracy                           0.94      4346\n",
      "   macro avg       0.48      0.77      0.57      4346\n",
      "weighted avg       0.97      0.94      0.95      4346\n",
      "\n",
      "Epoch: 610, train_loss: 0.1033, val_loss: 0.1808\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9338079266205763\n",
      "test accuracy: 0.9307409111826968\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.98      0.71        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.47      1.00      0.64        17\n",
      "           3       0.41      0.96      0.57       168\n",
      "           4       1.00      0.93      0.96      4112\n",
      "\n",
      "    accuracy                           0.93      4346\n",
      "   macro avg       0.49      0.77      0.58      4346\n",
      "weighted avg       0.97      0.93      0.94      4346\n",
      "\n",
      "Epoch: 620, train_loss: 0.0938, val_loss: 0.1950\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9356218769251831\n",
      "test accuracy: 0.9330418775885873\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.98      0.71        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.50      1.00      0.67        17\n",
      "           3       0.42      0.96      0.58       168\n",
      "           4       1.00      0.93      0.96      4112\n",
      "\n",
      "    accuracy                           0.93      4346\n",
      "   macro avg       0.49      0.77      0.58      4346\n",
      "weighted avg       0.97      0.93      0.94      4346\n",
      "\n",
      "Epoch: 630, train_loss: 0.0867, val_loss: 0.1898\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9376411800944623\n",
      "test accuracy: 0.9339622641509434\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.98      0.71        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.46      1.00      0.63        17\n",
      "           3       0.42      0.96      0.59       168\n",
      "           4       1.00      0.93      0.96      4112\n",
      "\n",
      "    accuracy                           0.93      4346\n",
      "   macro avg       0.49      0.77      0.58      4346\n",
      "weighted avg       0.97      0.93      0.95      4346\n",
      "\n",
      "Epoch: 640, train_loss: 0.0909, val_loss: 0.1852\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9383256896433705\n",
      "test accuracy: 0.9337321675103544\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.98      0.69        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.49      1.00      0.65        17\n",
      "           3       0.42      0.96      0.59       168\n",
      "           4       1.00      0.93      0.96      4112\n",
      "\n",
      "    accuracy                           0.93      4346\n",
      "   macro avg       0.49      0.77      0.58      4346\n",
      "weighted avg       0.97      0.93      0.94      4346\n",
      "\n",
      "Epoch: 650, train_loss: 0.0888, val_loss: 0.1816\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9393182284892875\n",
      "test accuracy: 0.9358030372756557\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.98      0.70        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.49      1.00      0.65        17\n",
      "           3       0.43      0.96      0.60       168\n",
      "           4       1.00      0.93      0.96      4112\n",
      "\n",
      "    accuracy                           0.94      4346\n",
      "   macro avg       0.49      0.77      0.58      4346\n",
      "weighted avg       0.97      0.94      0.95      4346\n",
      "\n",
      "Epoch: 660, train_loss: 0.0881, val_loss: 0.1790\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9361694845643097\n",
      "test accuracy: 0.93235158766682\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.98      0.73        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.53      1.00      0.69        17\n",
      "           3       0.41      0.96      0.57       168\n",
      "           4       1.00      0.93      0.96      4112\n",
      "\n",
      "    accuracy                           0.93      4346\n",
      "   macro avg       0.50      0.77      0.59      4346\n",
      "weighted avg       0.97      0.93      0.94      4346\n",
      "\n",
      "Epoch: 670, train_loss: 0.0883, val_loss: 0.1883\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9506810870011637\n",
      "test accuracy: 0.9479981592268752\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.98      0.74        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.49      1.00      0.65        17\n",
      "           3       0.49      0.93      0.64       168\n",
      "           4       1.00      0.95      0.97      4112\n",
      "\n",
      "    accuracy                           0.95      4346\n",
      "   macro avg       0.51      0.77      0.60      4346\n",
      "weighted avg       0.97      0.95      0.96      4346\n",
      "\n",
      "Epoch: 680, train_loss: 0.0861, val_loss: 0.1479\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9356218769251831\n",
      "test accuracy: 0.9314312011044639\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.98      0.74        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.53      1.00      0.69        17\n",
      "           3       0.40      0.96      0.57       168\n",
      "           4       1.00      0.93      0.96      4112\n",
      "\n",
      "    accuracy                           0.93      4346\n",
      "   macro avg       0.50      0.77      0.59      4346\n",
      "weighted avg       0.97      0.93      0.94      4346\n",
      "\n",
      "Epoch: 690, train_loss: 0.0914, val_loss: 0.1902\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9447258539256622\n",
      "test accuracy: 0.9406350667280258\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.98      0.73        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.52      1.00      0.68        17\n",
      "           3       0.45      0.95      0.61       168\n",
      "           4       1.00      0.94      0.97      4112\n",
      "\n",
      "    accuracy                           0.94      4346\n",
      "   macro avg       0.51      0.77      0.60      4346\n",
      "weighted avg       0.97      0.94      0.95      4346\n",
      "\n",
      "Epoch: 700, train_loss: 0.0885, val_loss: 0.1619\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.944041344376754\n",
      "test accuracy: 0.9390243902439024\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.98      0.73        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.52      1.00      0.68        17\n",
      "           3       0.44      0.95      0.60       168\n",
      "           4       1.00      0.94      0.97      4112\n",
      "\n",
      "    accuracy                           0.94      4346\n",
      "   macro avg       0.51      0.77      0.59      4346\n",
      "weighted avg       0.97      0.94      0.95      4346\n",
      "\n",
      "Epoch: 710, train_loss: 0.0906, val_loss: 0.1673\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9433226093504005\n",
      "test accuracy: 0.9376438104003681\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.98      0.74        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.50      1.00      0.67        17\n",
      "           3       0.43      0.95      0.59       168\n",
      "           4       1.00      0.94      0.97      4112\n",
      "\n",
      "    accuracy                           0.94      4346\n",
      "   macro avg       0.51      0.77      0.59      4346\n",
      "weighted avg       0.97      0.94      0.95      4346\n",
      "\n",
      "Epoch: 720, train_loss: 0.0919, val_loss: 0.1694\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9517763022794168\n",
      "test accuracy: 0.9479981592268752\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.98      0.75        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.61      1.00      0.76        17\n",
      "           3       0.48      0.93      0.63       168\n",
      "           4       1.00      0.95      0.97      4112\n",
      "\n",
      "    accuracy                           0.95      4346\n",
      "   macro avg       0.54      0.77      0.62      4346\n",
      "weighted avg       0.97      0.95      0.96      4346\n",
      "\n",
      "Epoch: 730, train_loss: 0.0789, val_loss: 0.1449\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.943288383872955\n",
      "test accuracy: 0.9385641969627243\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.98      0.76        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.55      1.00      0.71        17\n",
      "           3       0.43      0.95      0.59       168\n",
      "           4       1.00      0.94      0.97      4112\n",
      "\n",
      "    accuracy                           0.94      4346\n",
      "   macro avg       0.52      0.77      0.61      4346\n",
      "weighted avg       0.97      0.94      0.95      4346\n",
      "\n",
      "Epoch: 740, train_loss: 0.0773, val_loss: 0.1726\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9503730577041549\n",
      "test accuracy: 0.946617579383341\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.98      0.76        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.55      1.00      0.71        17\n",
      "           3       0.47      0.94      0.63       168\n",
      "           4       1.00      0.95      0.97      4112\n",
      "\n",
      "    accuracy                           0.95      4346\n",
      "   macro avg       0.53      0.77      0.61      4346\n",
      "weighted avg       0.97      0.95      0.95      4346\n",
      "\n",
      "Epoch: 750, train_loss: 0.0748, val_loss: 0.1500\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9456499418166884\n",
      "test accuracy: 0.941785549930971\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.98      0.75        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.53      1.00      0.69        17\n",
      "           3       0.45      0.95      0.61       168\n",
      "           4       1.00      0.94      0.97      4112\n",
      "\n",
      "    accuracy                           0.94      4346\n",
      "   macro avg       0.52      0.77      0.60      4346\n",
      "weighted avg       0.97      0.94      0.95      4346\n",
      "\n",
      "Epoch: 760, train_loss: 0.0842, val_loss: 0.1628\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9496200972003559\n",
      "test accuracy: 0.9443166129774505\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.98      0.75        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.59      1.00      0.74        17\n",
      "           3       0.46      0.94      0.62       168\n",
      "           4       1.00      0.94      0.97      4112\n",
      "\n",
      "    accuracy                           0.94      4346\n",
      "   macro avg       0.53      0.77      0.62      4346\n",
      "weighted avg       0.97      0.94      0.95      4346\n",
      "\n",
      "Epoch: 770, train_loss: 0.0771, val_loss: 0.1542\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.948285303579985\n",
      "test accuracy: 0.9431661297745053\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.98      0.76        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.59      1.00      0.74        17\n",
      "           3       0.45      0.95      0.61       168\n",
      "           4       1.00      0.94      0.97      4112\n",
      "\n",
      "    accuracy                           0.94      4346\n",
      "   macro avg       0.53      0.77      0.62      4346\n",
      "weighted avg       0.97      0.94      0.95      4346\n",
      "\n",
      "Epoch: 780, train_loss: 0.0797, val_loss: 0.1563\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9518447532343076\n",
      "test accuracy: 0.9456971928209849\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.98      0.77        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.61      1.00      0.76        17\n",
      "           3       0.46      0.93      0.62       168\n",
      "           4       1.00      0.95      0.97      4112\n",
      "\n",
      "    accuracy                           0.95      4346\n",
      "   macro avg       0.54      0.77      0.62      4346\n",
      "weighted avg       0.97      0.95      0.95      4346\n",
      "\n",
      "Epoch: 790, train_loss: 0.0790, val_loss: 0.1492\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9471900883017318\n",
      "test accuracy: 0.9429360331339163\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.98      0.75        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.53      1.00      0.69        17\n",
      "           3       0.46      0.95      0.62       168\n",
      "           4       1.00      0.94      0.97      4112\n",
      "\n",
      "    accuracy                           0.94      4346\n",
      "   macro avg       0.52      0.77      0.61      4346\n",
      "weighted avg       0.97      0.94      0.95      4346\n",
      "\n",
      "Epoch: 800, train_loss: 0.0787, val_loss: 0.1595\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9550619481141762\n",
      "test accuracy: 0.9491486424298206\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.98      0.74        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.59      1.00      0.74        17\n",
      "           3       0.49      0.93      0.64       168\n",
      "           4       1.00      0.95      0.97      4112\n",
      "\n",
      "    accuracy                           0.95      4346\n",
      "   macro avg       0.53      0.77      0.62      4346\n",
      "weighted avg       0.97      0.95      0.96      4346\n",
      "\n",
      "Epoch: 810, train_loss: 0.0739, val_loss: 0.1394\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9480114997604216\n",
      "test accuracy: 0.94201564657156\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.98      0.76        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.52      1.00      0.68        17\n",
      "           3       0.45      0.94      0.61       168\n",
      "           4       1.00      0.94      0.97      4112\n",
      "\n",
      "    accuracy                           0.94      4346\n",
      "   macro avg       0.52      0.77      0.60      4346\n",
      "weighted avg       0.97      0.94      0.95      4346\n",
      "\n",
      "Epoch: 820, train_loss: 0.0715, val_loss: 0.1573\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9504415086590458\n",
      "test accuracy: 0.9450069028992176\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.98      0.77        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.57      1.00      0.72        17\n",
      "           3       0.46      0.95      0.62       168\n",
      "           4       1.00      0.94      0.97      4112\n",
      "\n",
      "    accuracy                           0.95      4346\n",
      "   macro avg       0.53      0.77      0.62      4346\n",
      "weighted avg       0.97      0.95      0.95      4346\n",
      "\n",
      "Epoch: 830, train_loss: 0.0703, val_loss: 0.1547\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9469162844821686\n",
      "test accuracy: 0.94201564657156\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.98      0.77        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.61      1.00      0.76        17\n",
      "           3       0.44      0.95      0.60       168\n",
      "           4       1.00      0.94      0.97      4112\n",
      "\n",
      "    accuracy                           0.94      4346\n",
      "   macro avg       0.54      0.77      0.62      4346\n",
      "weighted avg       0.97      0.94      0.95      4346\n",
      "\n",
      "Epoch: 840, train_loss: 0.0798, val_loss: 0.1608\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9504072831816004\n",
      "test accuracy: 0.9443166129774505\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.98      0.78        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.61      1.00      0.76        17\n",
      "           3       0.45      0.94      0.61       168\n",
      "           4       1.00      0.94      0.97      4112\n",
      "\n",
      "    accuracy                           0.94      4346\n",
      "   macro avg       0.54      0.77      0.62      4346\n",
      "weighted avg       0.97      0.94      0.95      4346\n",
      "\n",
      "Epoch: 850, train_loss: 0.0806, val_loss: 0.1523\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9550277226367307\n",
      "test accuracy: 0.9500690289921767\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.98      0.76        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.52      1.00      0.68        17\n",
      "           3       0.50      0.93      0.65       168\n",
      "           4       1.00      0.95      0.97      4112\n",
      "\n",
      "    accuracy                           0.95      4346\n",
      "   macro avg       0.53      0.77      0.61      4346\n",
      "weighted avg       0.97      0.95      0.96      4346\n",
      "\n",
      "Epoch: 860, train_loss: 0.0713, val_loss: 0.1432\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9592032308850709\n",
      "test accuracy: 0.9546709618039576\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.98      0.77        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.57      1.00      0.72        17\n",
      "           3       0.52      0.92      0.67       168\n",
      "           4       1.00      0.96      0.98      4112\n",
      "\n",
      "    accuracy                           0.95      4346\n",
      "   macro avg       0.54      0.77      0.63      4346\n",
      "weighted avg       0.97      0.95      0.96      4346\n",
      "\n",
      "Epoch: 870, train_loss: 0.0717, val_loss: 0.1313\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9522212334862071\n",
      "test accuracy: 0.9475379659456972\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.98      0.73        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.63      1.00      0.77        17\n",
      "           3       0.48      0.93      0.64       168\n",
      "           4       1.00      0.95      0.97      4112\n",
      "\n",
      "    accuracy                           0.95      4346\n",
      "   macro avg       0.54      0.77      0.62      4346\n",
      "weighted avg       0.97      0.95      0.96      4346\n",
      "\n",
      "Epoch: 880, train_loss: 0.0737, val_loss: 0.1515\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9564994181668834\n",
      "test accuracy: 0.9502991256327658\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.98      0.75        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.50      1.00      0.67        17\n",
      "           3       0.50      0.93      0.66       168\n",
      "           4       1.00      0.95      0.97      4112\n",
      "\n",
      "    accuracy                           0.95      4346\n",
      "   macro avg       0.52      0.77      0.61      4346\n",
      "weighted avg       0.97      0.95      0.96      4346\n",
      "\n",
      "Epoch: 890, train_loss: 0.0749, val_loss: 0.1349\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9507837634334999\n",
      "test accuracy: 0.9452369995398067\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.98      0.74        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.55      1.00      0.71        17\n",
      "           3       0.47      0.95      0.63       168\n",
      "           4       1.00      0.94      0.97      4112\n",
      "\n",
      "    accuracy                           0.95      4346\n",
      "   macro avg       0.52      0.77      0.61      4346\n",
      "weighted avg       0.97      0.95      0.95      4346\n",
      "\n",
      "Epoch: 900, train_loss: 0.0798, val_loss: 0.1513\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9588952015880622\n",
      "test accuracy: 0.9553612517257248\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.98      0.77        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.52      1.00      0.68        17\n",
      "           3       0.53      0.92      0.68       168\n",
      "           4       1.00      0.96      0.98      4112\n",
      "\n",
      "    accuracy                           0.96      4346\n",
      "   macro avg       0.54      0.77      0.62      4346\n",
      "weighted avg       0.97      0.96      0.96      4346\n",
      "\n",
      "Epoch: 910, train_loss: 0.0729, val_loss: 0.1302\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9550277226367307\n",
      "test accuracy: 0.9502991256327658\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.98      0.75        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.52      1.00      0.68        17\n",
      "           3       0.50      0.93      0.65       168\n",
      "           4       1.00      0.95      0.97      4112\n",
      "\n",
      "    accuracy                           0.95      4346\n",
      "   macro avg       0.52      0.77      0.61      4346\n",
      "weighted avg       0.97      0.95      0.96      4346\n",
      "\n",
      "Epoch: 920, train_loss: 0.0692, val_loss: 0.1435\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9522212334862071\n",
      "test accuracy: 0.946617579383341\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.98      0.77        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.55      1.00      0.71        17\n",
      "           3       0.47      0.93      0.62       168\n",
      "           4       1.00      0.95      0.97      4112\n",
      "\n",
      "    accuracy                           0.95      4346\n",
      "   macro avg       0.53      0.77      0.61      4346\n",
      "weighted avg       0.97      0.95      0.95      4346\n",
      "\n",
      "Epoch: 930, train_loss: 0.0718, val_loss: 0.1483\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9548223697720584\n",
      "test accuracy: 0.9479981592268752\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.98      0.75        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.52      1.00      0.68        17\n",
      "           3       0.49      0.93      0.64       168\n",
      "           4       1.00      0.95      0.97      4112\n",
      "\n",
      "    accuracy                           0.95      4346\n",
      "   macro avg       0.52      0.77      0.61      4346\n",
      "weighted avg       0.97      0.95      0.96      4346\n",
      "\n",
      "Epoch: 940, train_loss: 0.0702, val_loss: 0.1444\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9543089876103772\n",
      "test accuracy: 0.9486884491486425\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.98      0.76        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.55      1.00      0.71        17\n",
      "           3       0.49      0.93      0.64       168\n",
      "           4       1.00      0.95      0.97      4112\n",
      "\n",
      "    accuracy                           0.95      4346\n",
      "   macro avg       0.53      0.77      0.62      4346\n",
      "weighted avg       0.97      0.95      0.96      4346\n",
      "\n",
      "Epoch: 950, train_loss: 0.0697, val_loss: 0.1493\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9580053391744815\n",
      "test accuracy: 0.9532903819604234\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.98      0.79        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.61      1.00      0.76        17\n",
      "           3       0.50      0.93      0.65       168\n",
      "           4       1.00      0.95      0.97      4112\n",
      "\n",
      "    accuracy                           0.95      4346\n",
      "   macro avg       0.55      0.77      0.63      4346\n",
      "weighted avg       0.97      0.95      0.96      4346\n",
      "\n",
      "Epoch: 960, train_loss: 0.0652, val_loss: 0.1338\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9585871722910535\n",
      "test accuracy: 0.9532903819604234\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.98      0.77        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.57      1.00      0.72        17\n",
      "           3       0.51      0.92      0.66       168\n",
      "           4       1.00      0.95      0.97      4112\n",
      "\n",
      "    accuracy                           0.95      4346\n",
      "   macro avg       0.54      0.77      0.63      4346\n",
      "weighted avg       0.97      0.95      0.96      4346\n",
      "\n",
      "Epoch: 970, train_loss: 0.0689, val_loss: 0.1368\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9636183174755287\n",
      "test accuracy: 0.956281638288081\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.98      0.79        49\n",
      "           2       0.65      1.00      0.79        17\n",
      "           3       0.52      0.90      0.66       168\n",
      "           4       1.00      0.96      0.98      4112\n",
      "\n",
      "    accuracy                           0.96      4346\n",
      "   macro avg       0.71      0.96      0.80      4346\n",
      "weighted avg       0.97      0.96      0.96      4346\n",
      "\n",
      "Epoch: 980, train_loss: 0.0624, val_loss: 0.1231\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9615990143062496\n",
      "test accuracy: 0.9544408651633686\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.98      0.79        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.65      1.00      0.79        17\n",
      "           3       0.51      0.91      0.65       168\n",
      "           4       1.00      0.96      0.98      4112\n",
      "\n",
      "    accuracy                           0.95      4346\n",
      "   macro avg       0.56      0.77      0.64      4346\n",
      "weighted avg       0.97      0.95      0.96      4346\n",
      "\n",
      "Epoch: 990, train_loss: 0.0693, val_loss: 0.1283\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9571839277157916\n",
      "test accuracy: 0.9491486424298206\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.98      0.76        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.55      1.00      0.71        17\n",
      "           3       0.49      0.92      0.64       168\n",
      "           4       1.00      0.95      0.97      4112\n",
      "\n",
      "    accuracy                           0.95      4346\n",
      "   macro avg       0.53      0.77      0.62      4346\n",
      "weighted avg       0.97      0.95      0.96      4346\n",
      "\n",
      "Epoch: 1000, train_loss: 0.0670, val_loss: 0.1434\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9573550551030187\n",
      "test accuracy: 0.9519098021168891\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.98      0.79        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.59      1.00      0.74        17\n",
      "           3       0.50      0.93      0.65       168\n",
      "           4       1.00      0.95      0.97      4112\n",
      "\n",
      "    accuracy                           0.95      4346\n",
      "   macro avg       0.55      0.77      0.63      4346\n",
      "weighted avg       0.97      0.95      0.96      4346\n",
      "\n",
      "Epoch: 1010, train_loss: 0.0598, val_loss: 0.1393\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9659798754192621\n",
      "test accuracy: 0.9588127013345605\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.98      0.80        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.63      1.00      0.77        17\n",
      "           3       0.54      0.89      0.68       168\n",
      "           4       1.00      0.96      0.98      4112\n",
      "\n",
      "    accuracy                           0.96      4346\n",
      "   macro avg       0.57      0.77      0.65      4346\n",
      "weighted avg       0.97      0.96      0.96      4346\n",
      "\n",
      "Epoch: 1020, train_loss: 0.0638, val_loss: 0.1191\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9610856321445684\n",
      "test accuracy: 0.9544408651633686\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.98      0.79        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.61      1.00      0.76        17\n",
      "           3       0.51      0.92      0.66       168\n",
      "           4       1.00      0.96      0.98      4112\n",
      "\n",
      "    accuracy                           0.95      4346\n",
      "   macro avg       0.55      0.77      0.64      4346\n",
      "weighted avg       0.97      0.95      0.96      4346\n",
      "\n",
      "Epoch: 1030, train_loss: 0.0672, val_loss: 0.1323\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9622492983777123\n",
      "test accuracy: 0.9544408651633686\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.98      0.77        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.61      1.00      0.76        17\n",
      "           3       0.52      0.92      0.66       168\n",
      "           4       1.00      0.96      0.98      4112\n",
      "\n",
      "    accuracy                           0.95      4346\n",
      "   macro avg       0.55      0.77      0.63      4346\n",
      "weighted avg       0.97      0.95      0.96      4346\n",
      "\n",
      "Epoch: 1040, train_loss: 0.0642, val_loss: 0.1270\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.963139160791293\n",
      "test accuracy: 0.9553612517257248\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.98      0.77        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.65      1.00      0.79        17\n",
      "           3       0.52      0.91      0.66       168\n",
      "           4       1.00      0.96      0.98      4112\n",
      "\n",
      "    accuracy                           0.96      4346\n",
      "   macro avg       0.56      0.77      0.64      4346\n",
      "weighted avg       0.97      0.96      0.96      4346\n",
      "\n",
      "Epoch: 1050, train_loss: 0.0707, val_loss: 0.1254\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9647135327537819\n",
      "test accuracy: 0.9576622181316152\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.98      0.77        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.59      1.00      0.74        17\n",
      "           3       0.54      0.90      0.68       168\n",
      "           4       1.00      0.96      0.98      4112\n",
      "\n",
      "    accuracy                           0.96      4346\n",
      "   macro avg       0.55      0.77      0.63      4346\n",
      "weighted avg       0.97      0.96      0.96      4346\n",
      "\n",
      "Epoch: 1060, train_loss: 0.0640, val_loss: 0.1224\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9640290232048737\n",
      "test accuracy: 0.9569719282098481\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.98      0.77        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.68      1.00      0.81        17\n",
      "           3       0.53      0.90      0.67       168\n",
      "           4       1.00      0.96      0.98      4112\n",
      "\n",
      "    accuracy                           0.96      4346\n",
      "   macro avg       0.57      0.77      0.65      4346\n",
      "weighted avg       0.97      0.96      0.96      4346\n",
      "\n",
      "Epoch: 1070, train_loss: 0.0594, val_loss: 0.1246\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9666643849681703\n",
      "test accuracy: 0.9590427979751496\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.98      0.78        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.61      1.00      0.76        17\n",
      "           3       0.55      0.89      0.68       168\n",
      "           4       1.00      0.96      0.98      4112\n",
      "\n",
      "    accuracy                           0.96      4346\n",
      "   macro avg       0.56      0.77      0.64      4346\n",
      "weighted avg       0.97      0.96      0.96      4346\n",
      "\n",
      "Epoch: 1080, train_loss: 0.0610, val_loss: 0.1205\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9642343760695462\n",
      "test accuracy: 0.9585826046939715\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.98      0.77        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.65      1.00      0.79        17\n",
      "           3       0.55      0.91      0.68       168\n",
      "           4       1.00      0.96      0.98      4112\n",
      "\n",
      "    accuracy                           0.96      4346\n",
      "   macro avg       0.57      0.77      0.65      4346\n",
      "weighted avg       0.97      0.96      0.96      4346\n",
      "\n",
      "Epoch: 1090, train_loss: 0.0663, val_loss: 0.1254\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9657060715996988\n",
      "test accuracy: 0.9590427979751496\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.98      0.82        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.61      1.00      0.76        17\n",
      "           3       0.54      0.90      0.68       168\n",
      "           4       1.00      0.96      0.98      4112\n",
      "\n",
      "    accuracy                           0.96      4346\n",
      "   macro avg       0.57      0.77      0.65      4346\n",
      "weighted avg       0.97      0.96      0.96      4346\n",
      "\n",
      "Epoch: 1100, train_loss: 0.0588, val_loss: 0.1213\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9665617085358341\n",
      "test accuracy: 0.9588127013345605\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.98      0.81        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.61      1.00      0.76        17\n",
      "           3       0.54      0.89      0.68       168\n",
      "           4       1.00      0.96      0.98      4112\n",
      "\n",
      "    accuracy                           0.96      4346\n",
      "   macro avg       0.57      0.77      0.64      4346\n",
      "weighted avg       0.97      0.96      0.96      4346\n",
      "\n",
      "Epoch: 1110, train_loss: 0.0613, val_loss: 0.1200\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9663563556711616\n",
      "test accuracy: 0.9578923147722044\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.98      0.79        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.61      1.00      0.76        17\n",
      "           3       0.54      0.91      0.68       168\n",
      "           4       1.00      0.96      0.98      4112\n",
      "\n",
      "    accuracy                           0.96      4346\n",
      "   macro avg       0.56      0.77      0.64      4346\n",
      "weighted avg       0.97      0.96      0.96      4346\n",
      "\n",
      "Epoch: 1120, train_loss: 0.0600, val_loss: 0.1220\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9680334040659867\n",
      "test accuracy: 0.9595029912563277\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.98      0.79        49\n",
      "           2       0.68      1.00      0.81        17\n",
      "           3       0.55      0.89      0.68       168\n",
      "           4       1.00      0.96      0.98      4112\n",
      "\n",
      "    accuracy                           0.96      4346\n",
      "   macro avg       0.72      0.96      0.81      4346\n",
      "weighted avg       0.97      0.96      0.96      4346\n",
      "\n",
      "Epoch: 1130, train_loss: 0.0517, val_loss: 0.1180\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9610856321445684\n",
      "test accuracy: 0.9523699953980672\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.98      0.81        49\n",
      "           2       0.65      1.00      0.79        17\n",
      "           3       0.49      0.92      0.64       168\n",
      "           4       1.00      0.95      0.97      4112\n",
      "\n",
      "    accuracy                           0.95      4346\n",
      "   macro avg       0.71      0.96      0.80      4346\n",
      "weighted avg       0.97      0.95      0.96      4346\n",
      "\n",
      "Epoch: 1140, train_loss: 0.0554, val_loss: 0.1331\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9657745225545896\n",
      "test accuracy: 0.9581224114127934\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.98      0.81        49\n",
      "           2       0.59      1.00      0.74        17\n",
      "           3       0.53      0.91      0.67       168\n",
      "           4       1.00      0.96      0.98      4112\n",
      "\n",
      "    accuracy                           0.96      4346\n",
      "   macro avg       0.70      0.96      0.80      4346\n",
      "weighted avg       0.97      0.96      0.96      4346\n",
      "\n",
      "Epoch: 1150, train_loss: 0.0543, val_loss: 0.1219\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9639947977274282\n",
      "test accuracy: 0.95651173492867\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.98      0.77        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.55      1.00      0.71        17\n",
      "           3       0.54      0.90      0.67       168\n",
      "           4       1.00      0.96      0.98      4112\n",
      "\n",
      "    accuracy                           0.96      4346\n",
      "   macro avg       0.54      0.77      0.63      4346\n",
      "weighted avg       0.97      0.96      0.96      4346\n",
      "\n",
      "Epoch: 1160, train_loss: 0.0607, val_loss: 0.1279\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9658087480320351\n",
      "test accuracy: 0.9581224114127934\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.98      0.79        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.63      1.00      0.77        17\n",
      "           3       0.54      0.90      0.68       168\n",
      "           4       1.00      0.96      0.98      4112\n",
      "\n",
      "    accuracy                           0.96      4346\n",
      "   macro avg       0.56      0.77      0.64      4346\n",
      "weighted avg       0.97      0.96      0.96      4346\n",
      "\n",
      "Epoch: 1170, train_loss: 0.0559, val_loss: 0.1224\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9686836881374495\n",
      "test accuracy: 0.961113667740451\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.98      0.79        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.63      1.00      0.77        17\n",
      "           3       0.57      0.90      0.70       168\n",
      "           4       1.00      0.96      0.98      4112\n",
      "\n",
      "    accuracy                           0.96      4346\n",
      "   macro avg       0.57      0.77      0.65      4346\n",
      "weighted avg       0.97      0.96      0.97      4346\n",
      "\n",
      "Epoch: 1180, train_loss: 0.0551, val_loss: 0.1166\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9694708741186939\n",
      "test accuracy: 0.9620340543028072\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.98      0.80        49\n",
      "           2       0.63      1.00      0.77        17\n",
      "           3       0.57      0.90      0.70       168\n",
      "           4       1.00      0.96      0.98      4112\n",
      "\n",
      "    accuracy                           0.96      4346\n",
      "   macro avg       0.72      0.96      0.81      4346\n",
      "weighted avg       0.97      0.96      0.97      4346\n",
      "\n",
      "Epoch: 1190, train_loss: 0.0521, val_loss: 0.1157\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9710794715586283\n",
      "test accuracy: 0.9624942475839853\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.98      0.80        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.63      1.00      0.77        17\n",
      "           3       0.58      0.89      0.70       168\n",
      "           4       1.00      0.96      0.98      4112\n",
      "\n",
      "    accuracy                           0.96      4346\n",
      "   macro avg       0.58      0.77      0.65      4346\n",
      "weighted avg       0.97      0.96      0.97      4346\n",
      "\n",
      "Epoch: 1200, train_loss: 0.0595, val_loss: 0.1130\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.974981175987405\n",
      "test accuracy: 0.965945697192821\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.98      0.82        49\n",
      "           2       0.61      1.00      0.76        17\n",
      "           3       0.61      0.88      0.72       168\n",
      "           4       0.99      0.97      0.98      4112\n",
      "\n",
      "    accuracy                           0.97      4346\n",
      "   macro avg       0.73      0.96      0.82      4346\n",
      "weighted avg       0.97      0.97      0.97      4346\n",
      "\n",
      "Epoch: 1210, train_loss: 0.0527, val_loss: 0.1029\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.967143541652406\n",
      "test accuracy: 0.9585826046939715\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.98      0.81        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.68      1.00      0.81        17\n",
      "           3       0.53      0.90      0.67       168\n",
      "           4       1.00      0.96      0.98      4112\n",
      "\n",
      "    accuracy                           0.96      4346\n",
      "   macro avg       0.58      0.77      0.65      4346\n",
      "weighted avg       0.97      0.96      0.96      4346\n",
      "\n",
      "Epoch: 1220, train_loss: 0.0539, val_loss: 0.1227\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9689917174344582\n",
      "test accuracy: 0.9620340543028072\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.98      0.83        49\n",
      "           2       0.71      1.00      0.83        17\n",
      "           3       0.55      0.92      0.69       168\n",
      "           4       1.00      0.96      0.98      4112\n",
      "\n",
      "    accuracy                           0.96      4346\n",
      "   macro avg       0.74      0.96      0.83      4346\n",
      "weighted avg       0.97      0.96      0.97      4346\n",
      "\n",
      "Epoch: 1230, train_loss: 0.0557, val_loss: 0.1144\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9675200219043055\n",
      "test accuracy: 0.9590427979751496\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.98      0.80        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.68      1.00      0.81        17\n",
      "           3       0.54      0.91      0.68       168\n",
      "           4       1.00      0.96      0.98      4112\n",
      "\n",
      "    accuracy                           0.96      4346\n",
      "   macro avg       0.58      0.77      0.65      4346\n",
      "weighted avg       0.97      0.96      0.96      4346\n",
      "\n",
      "Epoch: 1240, train_loss: 0.0551, val_loss: 0.1234\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9697446779382572\n",
      "test accuracy: 0.9599631845375057\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.98      0.82        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.63      1.00      0.77        17\n",
      "           3       0.55      0.89      0.68       168\n",
      "           4       0.99      0.96      0.98      4112\n",
      "\n",
      "    accuracy                           0.96      4346\n",
      "   macro avg       0.58      0.77      0.65      4346\n",
      "weighted avg       0.97      0.96      0.96      4346\n",
      "\n",
      "Epoch: 1250, train_loss: 0.0561, val_loss: 0.1180\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9733383530700254\n",
      "test accuracy: 0.9624942475839853\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.98      0.79        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.65      1.00      0.79        17\n",
      "           3       0.58      0.87      0.70       168\n",
      "           4       0.99      0.97      0.98      4112\n",
      "\n",
      "    accuracy                           0.96      4346\n",
      "   macro avg       0.58      0.76      0.65      4346\n",
      "weighted avg       0.97      0.96      0.97      4346\n",
      "\n",
      "Epoch: 1260, train_loss: 0.0525, val_loss: 0.1091\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9680676295434322\n",
      "test accuracy: 0.9597330878969167\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.98      0.81        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.63      1.00      0.77        17\n",
      "           3       0.55      0.90      0.68       168\n",
      "           4       1.00      0.96      0.98      4112\n",
      "\n",
      "    accuracy                           0.96      4346\n",
      "   macro avg       0.57      0.77      0.65      4346\n",
      "weighted avg       0.97      0.96      0.96      4346\n",
      "\n",
      "Epoch: 1270, train_loss: 0.0527, val_loss: 0.1218\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9690943938667944\n",
      "test accuracy: 0.961113667740451\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.98      0.82        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.71      1.00      0.83        17\n",
      "           3       0.55      0.91      0.69       168\n",
      "           4       1.00      0.96      0.98      4112\n",
      "\n",
      "    accuracy                           0.96      4346\n",
      "   macro avg       0.59      0.77      0.66      4346\n",
      "weighted avg       0.97      0.96      0.97      4346\n",
      "\n",
      "Epoch: 1280, train_loss: 0.0541, val_loss: 0.1186\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9699842562803751\n",
      "test accuracy: 0.9597330878969167\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.98      0.81        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.59      1.00      0.74        17\n",
      "           3       0.55      0.90      0.69       168\n",
      "           4       1.00      0.96      0.98      4112\n",
      "\n",
      "    accuracy                           0.96      4346\n",
      "   macro avg       0.56      0.77      0.64      4346\n",
      "weighted avg       0.97      0.96      0.96      4346\n",
      "\n",
      "Epoch: 1290, train_loss: 0.0503, val_loss: 0.1175\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9666986104456157\n",
      "test accuracy: 0.9574321214910262\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.98      0.80        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.63      1.00      0.77        17\n",
      "           3       0.53      0.91      0.67       168\n",
      "           4       1.00      0.96      0.98      4112\n",
      "\n",
      "    accuracy                           0.96      4346\n",
      "   macro avg       0.57      0.77      0.64      4346\n",
      "weighted avg       0.97      0.96      0.96      4346\n",
      "\n",
      "Epoch: 1300, train_loss: 0.0613, val_loss: 0.1293\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9724484906564447\n",
      "test accuracy: 0.9620340543028072\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.98      0.81        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.65      1.00      0.79        17\n",
      "           3       0.57      0.90      0.70       168\n",
      "           4       1.00      0.96      0.98      4112\n",
      "\n",
      "    accuracy                           0.96      4346\n",
      "   macro avg       0.58      0.77      0.65      4346\n",
      "weighted avg       0.97      0.96      0.97      4346\n",
      "\n",
      "Epoch: 1310, train_loss: 0.0511, val_loss: 0.1131\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9729618728181259\n",
      "test accuracy: 0.9629544408651634\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.98      0.78        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.68      1.00      0.81        17\n",
      "           3       0.59      0.88      0.70       168\n",
      "           4       0.99      0.97      0.98      4112\n",
      "\n",
      "    accuracy                           0.96      4346\n",
      "   macro avg       0.58      0.76      0.65      4346\n",
      "weighted avg       0.97      0.96      0.97      4346\n",
      "\n",
      "Epoch: 1320, train_loss: 0.0517, val_loss: 0.1148\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9743308919159422\n",
      "test accuracy: 0.9631845375057524\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.98      0.81        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.63      1.00      0.77        17\n",
      "           3       0.58      0.88      0.70       168\n",
      "           4       0.99      0.97      0.98      4112\n",
      "\n",
      "    accuracy                           0.96      4346\n",
      "   macro avg       0.58      0.77      0.65      4346\n",
      "weighted avg       0.97      0.96      0.97      4346\n",
      "\n",
      "Epoch: 1330, train_loss: 0.0507, val_loss: 0.1077\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9690259429119036\n",
      "test accuracy: 0.9585826046939715\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.98      0.81        49\n",
      "           2       0.71      1.00      0.83        17\n",
      "           3       0.53      0.89      0.67       168\n",
      "           4       1.00      0.96      0.98      4112\n",
      "\n",
      "    accuracy                           0.96      4346\n",
      "   macro avg       0.73      0.96      0.82      4346\n",
      "weighted avg       0.97      0.96      0.96      4346\n",
      "\n",
      "Epoch: 1340, train_loss: 0.0518, val_loss: 0.1206\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9721062358819905\n",
      "test accuracy: 0.9620340543028072\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.98      0.81        49\n",
      "           2       0.71      1.00      0.83        17\n",
      "           3       0.56      0.89      0.69       168\n",
      "           4       0.99      0.96      0.98      4112\n",
      "\n",
      "    accuracy                           0.96      4346\n",
      "   macro avg       0.74      0.96      0.83      4346\n",
      "weighted avg       0.97      0.96      0.97      4346\n",
      "\n",
      "Epoch: 1350, train_loss: 0.0461, val_loss: 0.1150\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9749469505099596\n",
      "test accuracy: 0.9654855039116429\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.98      0.83        49\n",
      "           2       0.71      1.00      0.83        17\n",
      "           3       0.59      0.89      0.71       168\n",
      "           4       1.00      0.97      0.98      4112\n",
      "\n",
      "    accuracy                           0.97      4346\n",
      "   macro avg       0.75      0.96      0.84      4346\n",
      "weighted avg       0.98      0.97      0.97      4346\n",
      "\n",
      "Epoch: 1360, train_loss: 0.0510, val_loss: 0.1082\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9744335683482784\n",
      "test accuracy: 0.9641049240681087\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.98      0.83        49\n",
      "           2       0.71      1.00      0.83        17\n",
      "           3       0.58      0.89      0.70       168\n",
      "           4       0.99      0.97      0.98      4112\n",
      "\n",
      "    accuracy                           0.96      4346\n",
      "   macro avg       0.75      0.96      0.83      4346\n",
      "weighted avg       0.97      0.96      0.97      4346\n",
      "\n",
      "Epoch: 1370, train_loss: 0.0522, val_loss: 0.1099\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9761790676979943\n",
      "test accuracy: 0.9654855039116429\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.98      0.83        49\n",
      "           2       0.65      1.00      0.79        17\n",
      "           3       0.59      0.89      0.71       168\n",
      "           4       1.00      0.97      0.98      4112\n",
      "\n",
      "    accuracy                           0.97      4346\n",
      "   macro avg       0.74      0.96      0.83      4346\n",
      "weighted avg       0.98      0.97      0.97      4346\n",
      "\n",
      "Epoch: 1380, train_loss: 0.0441, val_loss: 0.1045\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9762132931754398\n",
      "test accuracy: 0.9657156005522319\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.98      0.83        49\n",
      "           2       0.65      1.00      0.79        17\n",
      "           3       0.60      0.88      0.71       168\n",
      "           4       0.99      0.97      0.98      4112\n",
      "\n",
      "    accuracy                           0.97      4346\n",
      "   macro avg       0.74      0.96      0.83      4346\n",
      "weighted avg       0.97      0.97      0.97      4346\n",
      "\n",
      "Epoch: 1390, train_loss: 0.0468, val_loss: 0.1063\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.97747963584092\n",
      "test accuracy: 0.96617579383341\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.98      0.81        49\n",
      "           2       0.71      1.00      0.83        17\n",
      "           3       0.60      0.87      0.71       168\n",
      "           4       0.99      0.97      0.98      4112\n",
      "\n",
      "    accuracy                           0.97      4346\n",
      "   macro avg       0.75      0.95      0.83      4346\n",
      "weighted avg       0.97      0.97      0.97      4346\n",
      "\n",
      "Epoch: 1400, train_loss: 0.0464, val_loss: 0.1028\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.972893421863235\n",
      "test accuracy: 0.9618039576622182\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.98      0.83        49\n",
      "           2       0.65      1.00      0.79        17\n",
      "           3       0.56      0.90      0.69       168\n",
      "           4       1.00      0.96      0.98      4112\n",
      "\n",
      "    accuracy                           0.96      4346\n",
      "   macro avg       0.73      0.96      0.82      4346\n",
      "weighted avg       0.97      0.96      0.97      4346\n",
      "\n",
      "Epoch: 1410, train_loss: 0.0509, val_loss: 0.1152\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9754945581490861\n",
      "test accuracy: 0.9629544408651634\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.98      0.79        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.71      1.00      0.83        17\n",
      "           3       0.60      0.86      0.71       168\n",
      "           4       0.99      0.97      0.98      4112\n",
      "\n",
      "    accuracy                           0.96      4346\n",
      "   macro avg       0.59      0.76      0.66      4346\n",
      "weighted avg       0.97      0.96      0.97      4346\n",
      "\n",
      "Epoch: 1420, train_loss: 0.0492, val_loss: 0.1095\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9738517352317064\n",
      "test accuracy: 0.9618039576622182\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.98      0.81        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.61      1.00      0.76        17\n",
      "           3       0.57      0.88      0.69       168\n",
      "           4       0.99      0.96      0.98      4112\n",
      "\n",
      "    accuracy                           0.96      4346\n",
      "   macro avg       0.57      0.76      0.65      4346\n",
      "weighted avg       0.97      0.96      0.97      4346\n",
      "\n",
      "Epoch: 1430, train_loss: 0.0525, val_loss: 0.1133\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9681703059757684\n",
      "test accuracy: 0.9572020248504371\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.98      0.78        49\n",
      "           2       0.71      1.00      0.83        17\n",
      "           3       0.53      0.91      0.67       168\n",
      "           4       1.00      0.96      0.98      4112\n",
      "\n",
      "    accuracy                           0.96      4346\n",
      "   macro avg       0.72      0.96      0.81      4346\n",
      "weighted avg       0.97      0.96      0.96      4346\n",
      "\n",
      "Epoch: 1440, train_loss: 0.0493, val_loss: 0.1298\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9747415976452871\n",
      "test accuracy: 0.9631845375057524\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.98      0.80        49\n",
      "           2       0.63      1.00      0.77        17\n",
      "           3       0.58      0.88      0.70       168\n",
      "           4       0.99      0.97      0.98      4112\n",
      "\n",
      "    accuracy                           0.96      4346\n",
      "   macro avg       0.72      0.96      0.81      4346\n",
      "weighted avg       0.97      0.96      0.97      4346\n",
      "\n",
      "Epoch: 1450, train_loss: 0.0475, val_loss: 0.1124\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9767951262920118\n",
      "test accuracy: 0.9643350207086977\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.98      0.81        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.68      1.00      0.81        17\n",
      "           3       0.60      0.86      0.70       168\n",
      "           4       0.99      0.97      0.98      4112\n",
      "\n",
      "    accuracy                           0.96      4346\n",
      "   macro avg       0.59      0.76      0.66      4346\n",
      "weighted avg       0.97      0.96      0.97      4346\n",
      "\n",
      "Epoch: 1460, train_loss: 0.0453, val_loss: 0.1062\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9765213224724485\n",
      "test accuracy: 0.9647952139898758\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.98      0.82        49\n",
      "           2       0.65      1.00      0.79        17\n",
      "           3       0.59      0.87      0.70       168\n",
      "           4       0.99      0.97      0.98      4112\n",
      "\n",
      "    accuracy                           0.96      4346\n",
      "   macro avg       0.74      0.95      0.82      4346\n",
      "weighted avg       0.97      0.96      0.97      4346\n",
      "\n",
      "Epoch: 1470, train_loss: 0.0470, val_loss: 0.1074\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9763501950852215\n",
      "test accuracy: 0.9645651173492867\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.98      0.82        49\n",
      "           2       0.71      1.00      0.83        17\n",
      "           3       0.58      0.89      0.70       168\n",
      "           4       0.99      0.97      0.98      4112\n",
      "\n",
      "    accuracy                           0.96      4346\n",
      "   macro avg       0.75      0.96      0.83      4346\n",
      "weighted avg       0.97      0.96      0.97      4346\n",
      "\n",
      "Epoch: 1480, train_loss: 0.0489, val_loss: 0.1085\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9785748511191731\n",
      "test accuracy: 0.9670961803957662\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.98      0.83        49\n",
      "           2       0.71      1.00      0.83        17\n",
      "           3       0.61      0.87      0.72       168\n",
      "           4       0.99      0.97      0.98      4112\n",
      "\n",
      "    accuracy                           0.97      4346\n",
      "   macro avg       0.76      0.95      0.84      4346\n",
      "weighted avg       0.98      0.97      0.97      4346\n",
      "\n",
      "Epoch: 1490, train_loss: 0.0437, val_loss: 0.1019\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9788144294612909\n",
      "test accuracy: 0.9670961803957662\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.98      0.82        49\n",
      "           2       0.71      1.00      0.83        17\n",
      "           3       0.61      0.86      0.72       168\n",
      "           4       0.99      0.97      0.98      4112\n",
      "\n",
      "    accuracy                           0.97      4346\n",
      "   macro avg       0.76      0.95      0.84      4346\n",
      "weighted avg       0.97      0.97      0.97      4346\n",
      "\n",
      "Epoch: 1500, train_loss: 0.0446, val_loss: 0.1036\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9786433020740639\n",
      "test accuracy: 0.9668660837551771\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.98      0.80        49\n",
      "           2       0.68      1.00      0.81        17\n",
      "           3       0.62      0.87      0.72       168\n",
      "           4       0.99      0.97      0.98      4112\n",
      "\n",
      "    accuracy                           0.97      4346\n",
      "   macro avg       0.74      0.95      0.83      4346\n",
      "weighted avg       0.97      0.97      0.97      4346\n",
      "\n",
      "Epoch: 1510, train_loss: 0.0438, val_loss: 0.1036\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9790882332808543\n",
      "test accuracy: 0.9680165669581224\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.98      0.81        49\n",
      "           2       0.71      1.00      0.83        17\n",
      "           3       0.62      0.89      0.73       168\n",
      "           4       1.00      0.97      0.98      4112\n",
      "\n",
      "    accuracy                           0.97      4346\n",
      "   macro avg       0.75      0.96      0.84      4346\n",
      "weighted avg       0.98      0.97      0.97      4346\n",
      "\n",
      "Epoch: 1520, train_loss: 0.0421, val_loss: 0.1016\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.977650763228147\n",
      "test accuracy: 0.9652554072710539\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.98      0.83        49\n",
      "           2       0.68      1.00      0.81        17\n",
      "           3       0.59      0.88      0.71       168\n",
      "           4       0.99      0.97      0.98      4112\n",
      "\n",
      "    accuracy                           0.97      4346\n",
      "   macro avg       0.75      0.96      0.83      4346\n",
      "weighted avg       0.97      0.97      0.97      4346\n",
      "\n",
      "Epoch: 1530, train_loss: 0.0429, val_loss: 0.1078\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9790882332808543\n",
      "test accuracy: 0.9682466635987115\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.98      0.84        49\n",
      "           2       0.71      1.00      0.83        17\n",
      "           3       0.61      0.88      0.72       168\n",
      "           4       0.99      0.97      0.98      4112\n",
      "\n",
      "    accuracy                           0.97      4346\n",
      "   macro avg       0.76      0.96      0.84      4346\n",
      "weighted avg       0.98      0.97      0.97      4346\n",
      "\n",
      "Epoch: 1540, train_loss: 0.0400, val_loss: 0.1025\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.982236977205832\n",
      "test accuracy: 0.9698573400828348\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.98      0.83        49\n",
      "           2       0.74      1.00      0.85        17\n",
      "           3       0.64      0.85      0.73       168\n",
      "           4       0.99      0.97      0.98      4112\n",
      "\n",
      "    accuracy                           0.97      4346\n",
      "   macro avg       0.77      0.95      0.85      4346\n",
      "weighted avg       0.98      0.97      0.97      4346\n",
      "\n",
      "Epoch: 1550, train_loss: 0.0414, val_loss: 0.0971\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9783010472996099\n",
      "test accuracy: 0.9668660837551771\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.98      0.84        49\n",
      "           2       0.68      1.00      0.81        17\n",
      "           3       0.60      0.88      0.71       168\n",
      "           4       0.99      0.97      0.98      4112\n",
      "\n",
      "    accuracy                           0.97      4346\n",
      "   macro avg       0.75      0.96      0.84      4346\n",
      "weighted avg       0.98      0.97      0.97      4346\n",
      "\n",
      "Epoch: 1560, train_loss: 0.0410, val_loss: 0.1027\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9800123211718803\n",
      "test accuracy: 0.9682466635987115\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.98      0.83        49\n",
      "           2       0.68      1.00      0.81        17\n",
      "           3       0.62      0.88      0.73       168\n",
      "           4       0.99      0.97      0.98      4112\n",
      "\n",
      "    accuracy                           0.97      4346\n",
      "   macro avg       0.75      0.96      0.84      4346\n",
      "weighted avg       0.98      0.97      0.97      4346\n",
      "\n",
      "Epoch: 1570, train_loss: 0.0475, val_loss: 0.1027\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9812102128824697\n",
      "test accuracy: 0.9680165669581224\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.98      0.82        49\n",
      "           2       0.71      1.00      0.83        17\n",
      "           3       0.62      0.86      0.72       168\n",
      "           4       0.99      0.97      0.98      4112\n",
      "\n",
      "    accuracy                           0.97      4346\n",
      "   macro avg       0.76      0.95      0.84      4346\n",
      "weighted avg       0.98      0.97      0.97      4346\n",
      "\n",
      "Epoch: 1580, train_loss: 0.0397, val_loss: 0.1002\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9809364090629065\n",
      "test accuracy: 0.9666359871145881\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.98      0.83        49\n",
      "           2       0.68      1.00      0.81        17\n",
      "           3       0.61      0.86      0.71       168\n",
      "           4       0.99      0.97      0.98      4112\n",
      "\n",
      "    accuracy                           0.97      4346\n",
      "   macro avg       0.75      0.95      0.83      4346\n",
      "weighted avg       0.97      0.97      0.97      4346\n",
      "\n",
      "Epoch: 1590, train_loss: 0.0420, val_loss: 0.1011\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9805257033335615\n",
      "test accuracy: 0.9675563736769444\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.98      0.81        49\n",
      "           2       0.71      1.00      0.83        17\n",
      "           3       0.62      0.86      0.72       168\n",
      "           4       0.99      0.97      0.98      4112\n",
      "\n",
      "    accuracy                           0.97      4346\n",
      "   macro avg       0.75      0.95      0.84      4346\n",
      "weighted avg       0.98      0.97      0.97      4346\n",
      "\n",
      "Epoch: 1600, train_loss: 0.0444, val_loss: 0.1045\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9747415976452871\n",
      "test accuracy: 0.9613437643810401\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.98      0.83        49\n",
      "           2       0.68      1.00      0.81        17\n",
      "           3       0.55      0.89      0.68       168\n",
      "           4       1.00      0.96      0.98      4112\n",
      "\n",
      "    accuracy                           0.96      4346\n",
      "   macro avg       0.74      0.96      0.82      4346\n",
      "weighted avg       0.97      0.96      0.97      4346\n",
      "\n",
      "Epoch: 1610, train_loss: 0.0540, val_loss: 0.1183\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.981073310972688\n",
      "test accuracy: 0.966405890473999\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.98      0.82        49\n",
      "           2       0.74      1.00      0.85        17\n",
      "           3       0.60      0.86      0.71       168\n",
      "           4       0.99      0.97      0.98      4112\n",
      "\n",
      "    accuracy                           0.97      4346\n",
      "   macro avg       0.76      0.95      0.84      4346\n",
      "weighted avg       0.97      0.97      0.97      4346\n",
      "\n",
      "Epoch: 1620, train_loss: 0.0425, val_loss: 0.1031\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9790882332808543\n",
      "test accuracy: 0.9647952139898758\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.98      0.83        49\n",
      "           2       0.68      1.00      0.81        17\n",
      "           3       0.58      0.89      0.70       168\n",
      "           4       0.99      0.97      0.98      4112\n",
      "\n",
      "    accuracy                           0.96      4346\n",
      "   macro avg       0.74      0.96      0.83      4346\n",
      "weighted avg       0.97      0.96      0.97      4346\n",
      "\n",
      "Epoch: 1630, train_loss: 0.0381, val_loss: 0.1075\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9774454103634745\n",
      "test accuracy: 0.9645651173492867\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.98      0.83        49\n",
      "           2       0.68      1.00      0.81        17\n",
      "           3       0.58      0.89      0.70       168\n",
      "           4       0.99      0.97      0.98      4112\n",
      "\n",
      "    accuracy                           0.96      4346\n",
      "   macro avg       0.74      0.96      0.83      4346\n",
      "weighted avg       0.97      0.96      0.97      4346\n",
      "\n",
      "Epoch: 1640, train_loss: 0.0417, val_loss: 0.1122\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9778561160928195\n",
      "test accuracy: 0.9641049240681087\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.98      0.82        49\n",
      "           2       0.68      1.00      0.81        17\n",
      "           3       0.58      0.89      0.70       168\n",
      "           4       1.00      0.97      0.98      4112\n",
      "\n",
      "    accuracy                           0.96      4346\n",
      "   macro avg       0.74      0.96      0.83      4346\n",
      "weighted avg       0.97      0.96      0.97      4346\n",
      "\n",
      "Epoch: 1650, train_loss: 0.0399, val_loss: 0.1132\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9796700663974263\n",
      "test accuracy: 0.9647952139898758\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.98      0.81        49\n",
      "           2       0.68      1.00      0.81        17\n",
      "           3       0.59      0.89      0.71       168\n",
      "           4       0.99      0.97      0.98      4112\n",
      "\n",
      "    accuracy                           0.96      4346\n",
      "   macro avg       0.74      0.96      0.83      4346\n",
      "weighted avg       0.97      0.96      0.97      4346\n",
      "\n",
      "Epoch: 1660, train_loss: 0.0415, val_loss: 0.1061\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.982236977205832\n",
      "test accuracy: 0.9682466635987115\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.98      0.83        49\n",
      "           2       0.68      1.00      0.81        17\n",
      "           3       0.62      0.87      0.73       168\n",
      "           4       0.99      0.97      0.98      4112\n",
      "\n",
      "    accuracy                           0.97      4346\n",
      "   macro avg       0.75      0.96      0.84      4346\n",
      "weighted avg       0.98      0.97      0.97      4346\n",
      "\n",
      "Epoch: 1670, train_loss: 0.0396, val_loss: 0.1010\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9828872612772949\n",
      "test accuracy: 0.9696272434422457\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.98      0.84        49\n",
      "           2       0.61      1.00      0.76        17\n",
      "           3       0.64      0.86      0.74       168\n",
      "           4       0.99      0.97      0.98      4112\n",
      "\n",
      "    accuracy                           0.97      4346\n",
      "   macro avg       0.75      0.95      0.83      4346\n",
      "weighted avg       0.98      0.97      0.97      4346\n",
      "\n",
      "Epoch: 1680, train_loss: 0.0375, val_loss: 0.1002\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9814155657471422\n",
      "test accuracy: 0.9675563736769444\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.98      0.84        49\n",
      "           2       0.74      1.00      0.85        17\n",
      "           3       0.61      0.87      0.71       168\n",
      "           4       0.99      0.97      0.98      4112\n",
      "\n",
      "    accuracy                           0.97      4346\n",
      "   macro avg       0.77      0.95      0.85      4346\n",
      "weighted avg       0.98      0.97      0.97      4346\n",
      "\n",
      "Epoch: 1690, train_loss: 0.0375, val_loss: 0.1036\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9830583886645219\n",
      "test accuracy: 0.9693971468016567\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.98      0.81        49\n",
      "           2       0.68      1.00      0.81        17\n",
      "           3       0.64      0.86      0.74       168\n",
      "           4       0.99      0.97      0.98      4112\n",
      "\n",
      "    accuracy                           0.97      4346\n",
      "   macro avg       0.75      0.95      0.84      4346\n",
      "weighted avg       0.98      0.97      0.97      4346\n",
      "\n",
      "Epoch: 1700, train_loss: 0.0385, val_loss: 0.0994\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9645766308440002\n",
      "test accuracy: 0.9553612517257248\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.98      0.81        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.71      1.00      0.83        17\n",
      "           3       0.51      0.92      0.66       168\n",
      "           4       1.00      0.96      0.98      4112\n",
      "\n",
      "    accuracy                           0.96      4346\n",
      "   macro avg       0.58      0.77      0.66      4346\n",
      "weighted avg       0.97      0.96      0.96      4346\n",
      "\n",
      "Epoch: 1710, train_loss: 0.0526, val_loss: 0.1392\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9783694982545007\n",
      "test accuracy: 0.9675563736769444\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.98      0.86        49\n",
      "           2       0.71      1.00      0.83        17\n",
      "           3       0.60      0.88      0.71       168\n",
      "           4       0.99      0.97      0.98      4112\n",
      "\n",
      "    accuracy                           0.97      4346\n",
      "   macro avg       0.77      0.96      0.85      4346\n",
      "weighted avg       0.98      0.97      0.97      4346\n",
      "\n",
      "Epoch: 1720, train_loss: 0.0490, val_loss: 0.1035\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9792935861455268\n",
      "test accuracy: 0.9677864703175334\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.98      0.83        49\n",
      "           2       0.68      1.00      0.81        17\n",
      "           3       0.61      0.89      0.73       168\n",
      "           4       1.00      0.97      0.98      4112\n",
      "\n",
      "    accuracy                           0.97      4346\n",
      "   macro avg       0.75      0.96      0.84      4346\n",
      "weighted avg       0.98      0.97      0.97      4346\n",
      "\n",
      "Epoch: 1730, train_loss: 0.0496, val_loss: 0.1039\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9836744472585393\n",
      "test accuracy: 0.9698573400828348\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.98      0.86        49\n",
      "           2       0.71      1.00      0.83        17\n",
      "           3       0.63      0.83      0.72       168\n",
      "           4       0.99      0.98      0.98      4112\n",
      "\n",
      "    accuracy                           0.97      4346\n",
      "   macro avg       0.78      0.95      0.85      4346\n",
      "weighted avg       0.98      0.97      0.97      4346\n",
      "\n",
      "Epoch: 1740, train_loss: 0.0455, val_loss: 0.0946\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.982408104593059\n",
      "test accuracy: 0.9675563736769444\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.98      0.84        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.68      1.00      0.81        17\n",
      "           3       0.62      0.85      0.71       168\n",
      "           4       0.99      0.97      0.98      4112\n",
      "\n",
      "    accuracy                           0.97      4346\n",
      "   macro avg       0.61      0.76      0.67      4346\n",
      "weighted avg       0.97      0.97      0.97      4346\n",
      "\n",
      "Epoch: 1750, train_loss: 0.0407, val_loss: 0.0991\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9845643096721199\n",
      "test accuracy: 0.9684767602393005\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.98      0.83        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.68      1.00      0.81        17\n",
      "           3       0.64      0.84      0.72       168\n",
      "           4       0.99      0.97      0.98      4112\n",
      "\n",
      "    accuracy                           0.97      4346\n",
      "   macro avg       0.61      0.76      0.67      4346\n",
      "weighted avg       0.97      0.97      0.97      4346\n",
      "\n",
      "Epoch: 1760, train_loss: 0.0414, val_loss: 0.0965\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.985146142788692\n",
      "test accuracy: 0.9698573400828348\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.98      0.86        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.68      1.00      0.81        17\n",
      "           3       0.64      0.82      0.72       168\n",
      "           4       0.99      0.98      0.98      4112\n",
      "\n",
      "    accuracy                           0.97      4346\n",
      "   macro avg       0.62      0.76      0.67      4346\n",
      "weighted avg       0.98      0.97      0.97      4346\n",
      "\n",
      "Epoch: 1770, train_loss: 0.0389, val_loss: 0.0974\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.986070230679718\n",
      "test accuracy: 0.9703175333640129\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.98      0.83        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.63      1.00      0.77        17\n",
      "           3       0.67      0.83      0.74       168\n",
      "           4       0.99      0.98      0.98      4112\n",
      "\n",
      "    accuracy                           0.97      4346\n",
      "   macro avg       0.60      0.76      0.67      4346\n",
      "weighted avg       0.98      0.97      0.97      4346\n",
      "\n",
      "Epoch: 1780, train_loss: 0.0375, val_loss: 0.0942\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9823738791156137\n",
      "test accuracy: 0.9680165669581224\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.98      0.84        49\n",
      "           2       0.65      1.00      0.79        17\n",
      "           3       0.62      0.87      0.72       168\n",
      "           4       0.99      0.97      0.98      4112\n",
      "\n",
      "    accuracy                           0.97      4346\n",
      "   macro avg       0.75      0.96      0.83      4346\n",
      "weighted avg       0.98      0.97      0.97      4346\n",
      "\n",
      "Epoch: 1790, train_loss: 0.0383, val_loss: 0.0982\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9840167020329934\n",
      "test accuracy: 0.9680165669581224\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.98      0.83        49\n",
      "           2       0.71      1.00      0.83        17\n",
      "           3       0.62      0.86      0.72       168\n",
      "           4       0.99      0.97      0.98      4112\n",
      "\n",
      "    accuracy                           0.97      4346\n",
      "   macro avg       0.76      0.95      0.84      4346\n",
      "weighted avg       0.98      0.97      0.97      4346\n",
      "\n",
      "Epoch: 1800, train_loss: 0.0372, val_loss: 0.0987\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9836744472585393\n",
      "test accuracy: 0.9684767602393005\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.98      0.83        49\n",
      "           2       0.71      1.00      0.83        17\n",
      "           3       0.63      0.86      0.72       168\n",
      "           4       0.99      0.97      0.98      4112\n",
      "\n",
      "    accuracy                           0.97      4346\n",
      "   macro avg       0.76      0.95      0.84      4346\n",
      "weighted avg       0.98      0.97      0.97      4346\n",
      "\n",
      "Epoch: 1810, train_loss: 0.0352, val_loss: 0.1000\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9848723389691286\n",
      "test accuracy: 0.9689369535204786\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.98      0.85        49\n",
      "           2       0.71      1.00      0.83        17\n",
      "           3       0.63      0.83      0.72       168\n",
      "           4       0.99      0.97      0.98      4112\n",
      "\n",
      "    accuracy                           0.97      4346\n",
      "   macro avg       0.77      0.95      0.84      4346\n",
      "weighted avg       0.97      0.97      0.97      4346\n",
      "\n",
      "Epoch: 1820, train_loss: 0.0314, val_loss: 0.0982\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9869600930932987\n",
      "test accuracy: 0.970547630004602\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.98      0.85        49\n",
      "           2       0.77      1.00      0.87        17\n",
      "           3       0.65      0.82      0.72       168\n",
      "           4       0.99      0.98      0.98      4112\n",
      "\n",
      "    accuracy                           0.97      4346\n",
      "   macro avg       0.79      0.94      0.86      4346\n",
      "weighted avg       0.98      0.97      0.97      4346\n",
      "\n",
      "Epoch: 1830, train_loss: 0.0337, val_loss: 0.0954\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9819631733862687\n",
      "test accuracy: 0.9673262770363553\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.96      0.85        49\n",
      "           2       0.71      1.00      0.83        17\n",
      "           3       0.60      0.85      0.70       168\n",
      "           4       0.99      0.97      0.98      4112\n",
      "\n",
      "    accuracy                           0.97      4346\n",
      "   macro avg       0.77      0.94      0.84      4346\n",
      "weighted avg       0.97      0.97      0.97      4346\n",
      "\n",
      "Epoch: 1840, train_loss: 0.0355, val_loss: 0.1085\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9837428982134301\n",
      "test accuracy: 0.9666359871145881\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.98      0.81        49\n",
      "           2       0.71      1.00      0.83        17\n",
      "           3       0.61      0.84      0.71       168\n",
      "           4       0.99      0.97      0.98      4112\n",
      "\n",
      "    accuracy                           0.97      4346\n",
      "   macro avg       0.75      0.95      0.83      4346\n",
      "weighted avg       0.97      0.97      0.97      4346\n",
      "\n",
      "Epoch: 1850, train_loss: 0.0346, val_loss: 0.1031\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9857279759052638\n",
      "test accuracy: 0.9691670501610676\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.98      0.83        49\n",
      "           2       0.71      1.00      0.83        17\n",
      "           3       0.64      0.82      0.72       168\n",
      "           4       0.99      0.97      0.98      4112\n",
      "\n",
      "    accuracy                           0.97      4346\n",
      "   macro avg       0.77      0.94      0.84      4346\n",
      "weighted avg       0.97      0.97      0.97      4346\n",
      "\n",
      "Epoch: 1860, train_loss: 0.0328, val_loss: 0.0976\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9863098090218358\n",
      "test accuracy: 0.9689369535204786\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.98      0.79        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.77      1.00      0.87        17\n",
      "           3       0.66      0.82      0.73       168\n",
      "           4       0.99      0.97      0.98      4112\n",
      "\n",
      "    accuracy                           0.97      4346\n",
      "   macro avg       0.62      0.75      0.68      4346\n",
      "weighted avg       0.97      0.97      0.97      4346\n",
      "\n",
      "Epoch: 1870, train_loss: 0.0383, val_loss: 0.1013\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9818604969539325\n",
      "test accuracy: 0.9645651173492867\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.96      0.85        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.68      1.00      0.81        17\n",
      "           3       0.58      0.86      0.70       168\n",
      "           4       0.99      0.97      0.98      4112\n",
      "\n",
      "    accuracy                           0.96      4346\n",
      "   macro avg       0.60      0.76      0.67      4346\n",
      "weighted avg       0.97      0.96      0.97      4346\n",
      "\n",
      "Epoch: 1880, train_loss: 0.0350, val_loss: 0.1081\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9847012115819016\n",
      "test accuracy: 0.9680165669581224\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.96      0.82        49\n",
      "           2       0.71      1.00      0.83        17\n",
      "           3       0.62      0.85      0.72       168\n",
      "           4       0.99      0.97      0.98      4112\n",
      "\n",
      "    accuracy                           0.97      4346\n",
      "   macro avg       0.76      0.95      0.84      4346\n",
      "weighted avg       0.97      0.97      0.97      4346\n",
      "\n",
      "Epoch: 1890, train_loss: 0.0353, val_loss: 0.1025\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9839140256006571\n",
      "test accuracy: 0.9682466635987115\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.98      0.83        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.63      1.00      0.77        17\n",
      "           3       0.63      0.87      0.73       168\n",
      "           4       0.99      0.97      0.98      4112\n",
      "\n",
      "    accuracy                           0.97      4346\n",
      "   macro avg       0.60      0.76      0.66      4346\n",
      "weighted avg       0.98      0.97      0.97      4346\n",
      "\n",
      "Epoch: 1900, train_loss: 0.0329, val_loss: 0.1021\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9883975631460059\n",
      "test accuracy: 0.9723884031293143\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.98      0.86        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.68      1.00      0.81        17\n",
      "           3       0.68      0.82      0.74       168\n",
      "           4       0.99      0.98      0.99      4112\n",
      "\n",
      "    accuracy                           0.97      4346\n",
      "   macro avg       0.62      0.75      0.68      4346\n",
      "weighted avg       0.98      0.97      0.97      4346\n",
      "\n",
      "Epoch: 1910, train_loss: 0.0339, val_loss: 0.0931\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9877472790745431\n",
      "test accuracy: 0.9710078232857801\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.98      0.86        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.71      1.00      0.83        17\n",
      "           3       0.66      0.83      0.73       168\n",
      "           4       0.99      0.98      0.98      4112\n",
      "\n",
      "    accuracy                           0.97      4346\n",
      "   macro avg       0.62      0.76      0.68      4346\n",
      "weighted avg       0.98      0.97      0.97      4346\n",
      "\n",
      "Epoch: 1920, train_loss: 0.0319, val_loss: 0.0953\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9855568485180368\n",
      "test accuracy: 0.9693971468016567\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.96      0.84        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.74      1.00      0.85        17\n",
      "           3       0.64      0.82      0.72       168\n",
      "           4       0.99      0.98      0.98      4112\n",
      "\n",
      "    accuracy                           0.97      4346\n",
      "   macro avg       0.62      0.75      0.68      4346\n",
      "weighted avg       0.97      0.97      0.97      4346\n",
      "\n",
      "Epoch: 1930, train_loss: 0.0336, val_loss: 0.1029\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.985899103292491\n",
      "test accuracy: 0.9700874367234238\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.98      0.83        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.71      1.00      0.83        17\n",
      "           3       0.65      0.84      0.73       168\n",
      "           4       0.99      0.98      0.98      4112\n",
      "\n",
      "    accuracy                           0.97      4346\n",
      "   macro avg       0.61      0.76      0.68      4346\n",
      "weighted avg       0.98      0.97      0.97      4346\n",
      "\n",
      "Epoch: 1940, train_loss: 0.0324, val_loss: 0.1019\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9882264357587789\n",
      "test accuracy: 0.9710078232857801\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.98      0.86        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.71      1.00      0.83        17\n",
      "           3       0.66      0.82      0.73       168\n",
      "           4       0.99      0.98      0.98      4112\n",
      "\n",
      "    accuracy                           0.97      4346\n",
      "   macro avg       0.62      0.75      0.68      4346\n",
      "weighted avg       0.98      0.97      0.97      4346\n",
      "\n",
      "Epoch: 1950, train_loss: 0.0293, val_loss: 0.0944\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9856252994729277\n",
      "test accuracy: 0.9693971468016567\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.98      0.84        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.71      1.00      0.83        17\n",
      "           3       0.64      0.85      0.73       168\n",
      "           4       0.99      0.97      0.98      4112\n",
      "\n",
      "    accuracy                           0.97      4346\n",
      "   macro avg       0.62      0.76      0.68      4346\n",
      "weighted avg       0.98      0.97      0.97      4346\n",
      "\n",
      "Epoch: 1960, train_loss: 0.0317, val_loss: 0.0998\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9879184064617701\n",
      "test accuracy: 0.9712379199263691\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.96      0.84        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.74      1.00      0.85        17\n",
      "           3       0.66      0.82      0.73       168\n",
      "           4       0.99      0.98      0.98      4112\n",
      "\n",
      "    accuracy                           0.97      4346\n",
      "   macro avg       0.63      0.75      0.68      4346\n",
      "weighted avg       0.98      0.97      0.97      4346\n",
      "\n",
      "Epoch: 1970, train_loss: 0.0343, val_loss: 0.0966\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9863782599767267\n",
      "test accuracy: 0.9703175333640129\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.98      0.84        49\n",
      "           2       0.74      1.00      0.85        17\n",
      "           3       0.65      0.83      0.73       168\n",
      "           4       0.99      0.98      0.98      4112\n",
      "\n",
      "    accuracy                           0.97      4346\n",
      "   macro avg       0.78      0.95      0.85      4346\n",
      "weighted avg       0.98      0.97      0.97      4346\n",
      "\n",
      "Epoch: 1980, train_loss: 0.0317, val_loss: 0.0995\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9862071325894997\n",
      "test accuracy: 0.9684767602393005\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.98      0.85        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.68      1.00      0.81        17\n",
      "           3       0.63      0.83      0.71       168\n",
      "           4       0.99      0.97      0.98      4112\n",
      "\n",
      "    accuracy                           0.97      4346\n",
      "   macro avg       0.61      0.76      0.67      4346\n",
      "weighted avg       0.97      0.97      0.97      4346\n",
      "\n",
      "Epoch: 1990, train_loss: 0.0298, val_loss: 0.1018\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train accuracy: 0.9864467109316175\n",
      "test accuracy: 0.9698573400828348\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.96      0.85        49\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.74      1.00      0.85        17\n",
      "           3       0.64      0.84      0.72       168\n",
      "           4       0.99      0.98      0.98      4112\n",
      "\n",
      "    accuracy                           0.97      4346\n",
      "   macro avg       0.63      0.75      0.68      4346\n",
      "weighted avg       0.98      0.97      0.97      4346\n",
      "\n",
      "Epoch: 2000, train_loss: 0.0313, val_loss: 0.1009\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
     ]
    }
   ],
   "source": [
    "epochs = 2000\n",
    "for epoch in range(0, epochs + 1):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss = F.nll_loss(model(train_data), train_data.y - 1,\n",
    "                      weight=torch.FloatTensor(_class_weights).to(device))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        if epoch % 10 == 0:\n",
    "            model.eval()\n",
    "\n",
    "            # forward model\n",
    "            for index, name in enumerate(['train', 'test']):\n",
    "                _data = eval(f'{name}_data')\n",
    "                y_pred = model(_data).max(dim=1)[1]\n",
    "                y_true = (_data.y - 1)\n",
    "                acc = y_pred.eq(y_true).sum().item() / y_pred.shape[0]\n",
    "\n",
    "                y_pred = y_pred.cpu().numpy()\n",
    "                y_true = y_true.cpu().numpy()\n",
    "                print(f'{name} accuracy: {acc}')\n",
    "\n",
    "                if name == 'test':\n",
    "                    print(\"test\")\n",
    "                    cm = confusion_matrix(y_true, y_pred)\n",
    "                    class_acc = cm.diagonal() / cm.sum(axis=1)\n",
    "                    print(classification_report(y_true, y_pred))\n",
    "\n",
    "            loss_val = F.nll_loss(model(test_data), test_data.y - 1)\n",
    "            print(f'Epoch: {epoch:3d}, train_loss: {loss:.4f}, val_loss: {loss_val:.4f}')\n",
    "            print('>' * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TorchEnv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
