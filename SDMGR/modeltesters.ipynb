{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn \n",
    "from torchinfo import summary\n",
    "\n",
    "from unet import UNet\n",
    "from VisionModel import VisionModel\n",
    "from transformer import TransformerEncoder\n",
    "from PreprocessingModule import DualityProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = UNet()\n",
    "# summary(model=model,\n",
    "#         input_size=(16, 1, 256, 256),\n",
    "#         col_names=['input_size', 'output_size', 'num_params', 'trainable'],\n",
    "#         col_width=20,\n",
    "#         row_settings=['var_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = VisionModel()\n",
    "# inp = torch.rand(4, 1, 4096, 4096)\n",
    "# rois = torch.tensor([\n",
    "#     [\n",
    "#         [102, 200, 300, 1500, 3500],   # Batch 1, Box 1\n",
    "#         [205, 400, 500, 1800, 3800]    # Batch 1, Box 2\n",
    "#     ],\n",
    "#     [\n",
    "#         [111, 250, 450, 1600, 3200],   # Batch 2, Box 1\n",
    "#         [215, 600, 700, 2000, 3400]    # Batch 2, Box 2\n",
    "#     ],\n",
    "#     [\n",
    "#         [120, 300, 600, 1300, 3100],   # Batch 3, Box 1\n",
    "#         [230, 500, 800, 1700, 3600]    # Batch 3, Box 2\n",
    "#     ],\n",
    "#     [\n",
    "#         [130, 100, 200, 1100, 2100],   # Batch 4, Box 1\n",
    "#         [240, 300, 400, 1200, 2200]    # Batch 4, Box 2\n",
    "#     ]\n",
    "# ])\n",
    "\n",
    "# summary(model=model,\n",
    "#         input_data=(inp, rois),\n",
    "#         col_names=['input_size', 'output_size', 'num_params', 'trainable'],\n",
    "#         col_width=20,\n",
    "#         row_settings=['var_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = TransformerEncoder()\n",
    "# inp = torch.randint(1, 4096, (4, 64, 5))\n",
    "\n",
    "# summary(model=model,\n",
    "#         input_data=inp,\n",
    "#         col_names=['input_size', 'output_size', 'num_params', 'trainable'],\n",
    "#         col_width=20,\n",
    "#         row_settings=['var_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 2, 7, 7])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "============================================================================================================================================\n",
       "Layer (type (var_name))                                      Input Shape          Output Shape         Param #              Trainable\n",
       "============================================================================================================================================\n",
       "DualityProcessor (DualityProcessor)                          [4, 1, 4096, 4096]   [4, 5, 512]          --                   True\n",
       "├─VisionModel (vision)                                       [4, 1, 4096, 4096]   [4, 3, 512]          --                   True\n",
       "│    └─UNet (unet)                                           [4, 1, 256, 256]     [4, 1, 256, 256]     --                   True\n",
       "│    │    └─EncoderBlock (encoder1)                          [4, 1, 256, 256]     [4, 32, 256, 256]    512                  True\n",
       "│    │    └─MaxPool2d (pool)                                 [4, 32, 256, 256]    [4, 32, 128, 128]    --                   --\n",
       "│    │    └─EncoderBlock (encoder2)                          [4, 32, 128, 128]    [4, 64, 128, 128]    20,864               True\n",
       "│    │    └─MaxPool2d (pool)                                 [4, 64, 128, 128]    [4, 64, 64, 64]      --                   --\n",
       "│    │    └─EncoderBlock (encoder3)                          [4, 64, 64, 64]      [4, 128, 64, 64]     82,688               True\n",
       "│    │    └─MaxPool2d (pool)                                 [4, 128, 64, 64]     [4, 128, 32, 32]     --                   --\n",
       "│    │    └─EncoderBlock (encoder4)                          [4, 128, 32, 32]     [4, 256, 32, 32]     329,216              True\n",
       "│    │    └─MaxPool2d (pool)                                 [4, 256, 32, 32]     [4, 256, 16, 16]     --                   --\n",
       "│    │    └─BottleNeckBlock (bottleneck)                     [4, 256, 16, 16]     [4, 512, 16, 16]     1,313,792            True\n",
       "│    │    └─AttentionBlock (att1)                            [4, 512, 16, 16]     [4, 256, 32, 32]     329,731              True\n",
       "│    │    └─DecoderBlock (decoder1)                          [4, 512, 16, 16]     [4, 256, 32, 32]     1,837,312            True\n",
       "│    │    └─AttentionBlock (att2)                            [4, 256, 32, 32]     [4, 128, 64, 64]     82,947               True\n",
       "│    │    └─DecoderBlock (decoder2)                          [4, 256, 32, 32]     [4, 128, 64, 64]     459,904              True\n",
       "│    │    └─AttentionBlock (att3)                            [4, 128, 64, 64]     [4, 64, 128, 128]    20,995               True\n",
       "│    │    └─DecoderBlock (decoder3)                          [4, 128, 64, 64]     [4, 64, 128, 128]    115,264              True\n",
       "│    │    └─AttentionBlock (att4)                            [4, 64, 128, 128]    [4, 32, 256, 256]    5,379                True\n",
       "│    │    └─DecoderBlock (decoder4)                          [4, 64, 128, 128]    [4, 32, 256, 256]    28,960               True\n",
       "│    │    └─Conv2d (output_conv)                             [4, 32, 256, 256]    [4, 1, 256, 256]     33                   True\n",
       "│    └─RoI (roi)                                             [4, 1, 256, 256]     [4, 2, 7, 7]         --                   --\n",
       "│    └─Linear (fc_out)                                       [4, 3, 49]           [4, 3, 512]          25,600               True\n",
       "├─TransformerEncoder (text)                                  [4, 2, 5]            [4, 2, 512]          65,536               True\n",
       "│    └─Embedding (word_embedder)                             [4, 2]               [4, 2, 512]          4,194,304            True\n",
       "│    └─Embedding (bbox_embedder)                             [4, 2]               [4, 2, 512]          4,194,304            True\n",
       "│    └─Embedding (bbox_embedder)                             [4, 2]               [4, 2, 512]          (recursive)          True\n",
       "│    └─Embedding (bbox_embedder)                             [4, 2]               [4, 2, 512]          (recursive)          True\n",
       "│    └─Embedding (bbox_embedder)                             [4, 2]               [4, 2, 512]          (recursive)          True\n",
       "│    └─TransformerEncoder (encoder)                          [4, 2, 512]          [4, 2, 512]          --                   True\n",
       "│    │    └─ModuleList (layers)                              --                   --                   5,262,336            True\n",
       "============================================================================================================================================\n",
       "Total params: 18,369,677\n",
       "Trainable params: 18,369,677\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 37.88\n",
       "============================================================================================================================================\n",
       "Input size (MB): 268.44\n",
       "Forward/backward pass size (MB): 1535.07\n",
       "Params size (MB): 56.41\n",
       "Estimated Total Size (MB): 1859.91\n",
       "============================================================================================================================================"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DualityProcessor()\n",
    "img = torch.rand(4, 1, 4096, 4096)\n",
    "rois = torch.tensor([\n",
    "    [\n",
    "        [102, 200, 300, 1500, 3500],   # Batch 1, Box 1\n",
    "        [205, 400, 500, 1800, 3800]    # Batch 1, Box 2\n",
    "    ],\n",
    "    [\n",
    "        [111, 250, 450, 1600, 3200],   # Batch 2, Box 1\n",
    "        [215, 600, 700, 2000, 3400]    # Batch 2, Box 2\n",
    "    ],\n",
    "    [\n",
    "        [120, 300, 600, 1300, 3100],   # Batch 3, Box 1\n",
    "        [230, 500, 800, 1700, 3600]    # Batch 3, Box 2\n",
    "    ],\n",
    "    [\n",
    "        [130, 100, 200, 1100, 2100],   # Batch 4, Box 1\n",
    "        [240, 300, 400, 1200, 2200]    # Batch 4, Box 2\n",
    "    ]\n",
    "])\n",
    "summary(model=model,\n",
    "        input_data=(img, rois),\n",
    "        col_names=['input_size', 'output_size', 'num_params', 'trainable'],\n",
    "        col_width=20,\n",
    "        row_settings=['var_names'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TorchEnv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
